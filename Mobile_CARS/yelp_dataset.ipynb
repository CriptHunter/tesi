{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regional-background",
   "metadata": {
    "id": "dn7d0bVYO2H1"
   },
   "source": [
    "# Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-harvard",
   "metadata": {},
   "source": [
    "**User:**\n",
    "- name\n",
    "- friend list\n",
    "**Tip:** Niente\n",
    "\n",
    "**Review:**\n",
    "- user id\n",
    "- business id\n",
    "- stars\n",
    "- date\n",
    "\n",
    "**Checkin:** Niente\n",
    "\n",
    "**Business:**\n",
    "- categories\n",
    "- attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-lecture",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "increased-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged dataset already exists, skipping merge...\n"
     ]
    }
   ],
   "source": [
    "def merge_datasets():\n",
    "    if os.path.exists('Datasets/yelp dataset/yelp_dataset_merged.csv'):\n",
    "        print(\"merged dataset already exists, skipping merge...\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_json('Datasets/yelp dataset/yelp_academic_dataset_business.json', lines=True)\n",
    "    df = df[['business_id', 'city', 'categories', 'attributes']]\n",
    "    df = df[df.city == 'Toronto'] # keep only Toronto, the city with more rating\n",
    "    df = df[df['categories'].str.contains('Restaurant.*')==True].reset_index(drop=True) # keep only restaurant\n",
    "\n",
    "    chunk_list = []  # append each chunk df here \n",
    "    # open the big review dataset in little chunk\n",
    "    for chunk in tqdm(pd.read_json('Datasets/yelp dataset/yelp_academic_dataset_review.json', lines=True, chunksize=500000)):\n",
    "        chunk = chunk[['user_id', 'business_id', 'stars', 'date']]\n",
    "        chunk = pd.merge(chunk, df, on='business_id') # merge business dataset and review dataset chunk\n",
    "        chunk_list.append(chunk)\n",
    "    df = pd.concat(chunk_list)\n",
    "    df.to_csv('Datasets/yelp dataset/yelp_dataset_merged.csv', index = False) # save dataset to CSV file\n",
    "    \n",
    "merge_datasets()\n",
    "df = pd.read_csv('Datasets/yelp dataset/yelp_dataset_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "pleased-memphis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 174468 \t user: 3309 \t item:8362\n",
      " rating: 1    105110\n",
      "0     69358\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={'user_id':'user', 'business_id':'item', 'stars':'rating'})\n",
    "#df = df[(df.groupby('user')['user'].transform('size') > 10) & (df.groupby('item')['item'].transform('size') > 10)]\n",
    "df = df[(df.groupby('user')['user'].transform('size') > 20)]\n",
    "df['rating'] = df['rating'].apply(lambda x: 1 if x > 3 else 0) # make rating binary\n",
    "\n",
    "#df = df.groupby('rating').apply(lambda x: x.sample(40000))\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f'row: {len(df)} \\t user: {df.user.nunique()} \\t item:{df.item.nunique()}')\n",
    "\n",
    "# make user and items id start from 0\n",
    "df.user = pd.factorize(df.user)[0]\n",
    "df.item = pd.factorize(df.item)[0]\n",
    "\n",
    "\n",
    "print(f' rating: {df.rating.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-attachment",
   "metadata": {},
   "source": [
    "## Extract new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "focal-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_from_date(date):\n",
    "    seasons = np.arange(12)\n",
    "    seasons = seasons.reshape(4, 3) # reshape to a 2D matrix\n",
    "    i, j = np.where(seasons == date.month - 1) # get row where month appears\n",
    "    return i[0] + 1 # 1 = winter, 2 = spring, 3 = summer, 4 = autumn\n",
    "\n",
    "def holiday_from_date(date):\n",
    "    us_holidays = holidays.Canada()\n",
    "    return date in us_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "technological-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date']) # convert from string to datetime\n",
    "df['season'] = df['date'].apply(season_from_date)\n",
    "df['weekday'] = df['date'].dt.dayofweek # get day of the week from date (0 to 6)\n",
    "df['weekend'] = (df['weekday'] == 6) | (df['weekday'] == 5) # if is weekend from week day\n",
    "df['holiday'] = df['date'].apply(holiday_from_date) # get holiday in Canada from date\n",
    "df = df.drop(columns=['date', 'city', 'categories', 'attributes']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-community",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "promising-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = 'season weekday weekend holiday'.split()\n",
    "# convert categorical data to one-hot encoding\n",
    "for col in one_hot:\n",
    "  df = pd.get_dummies(df, columns=[col], prefix = [col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "empty-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/yelp dataset/yelp_final.csv', index = False) \n",
    "df = df.drop_duplicates(subset=['user', 'item']) # drop duplicates for matrix factorization\n",
    "df = df[['user', 'item', 'rating']]\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv('Datasets/yelp dataset/yelp_matrix_factorization.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
