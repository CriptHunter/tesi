{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "premium-superintendent",
   "metadata": {
    "id": "dn7d0bVYO2H1"
   },
   "source": [
    "# Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caroline-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-knife",
   "metadata": {},
   "source": [
    "**User:**\n",
    "- name\n",
    "- friend list\n",
    "**Tip:** Niente\n",
    "\n",
    "**Review:**\n",
    "- user id\n",
    "- business id\n",
    "- stars\n",
    "- date\n",
    "\n",
    "**Checkin:** Niente\n",
    "\n",
    "**Business:**\n",
    "- categories\n",
    "- attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-chile",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "liked-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged dataset already exists, skipping merge...\n"
     ]
    }
   ],
   "source": [
    "def merge_datasets():\n",
    "    if os.path.exists('Datasets/yelp dataset/yelp_dataset_merged.csv'):\n",
    "        print(\"merged dataset already exists, skipping merge...\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_json('Datasets/yelp dataset/yelp_academic_dataset_business.json', lines=True)\n",
    "    df = df[['business_id', 'city', 'categories', 'attributes']]\n",
    "    df = df[df.city == 'Toronto'] # keep only Toronto, the city with more rating\n",
    "    df = df[df['categories'].str.contains('Restaurant.*')==True].reset_index(drop=True) # keep only restaurant\n",
    "\n",
    "    chunk_list = []  # append each dataframe chunk here \n",
    "    for chunk in tqdm(pd.read_json('Datasets/yelp dataset/yelp_academic_dataset_review.json', lines=True, chunksize=500000)):\n",
    "        chunk = chunk[['user_id', 'business_id', 'stars', 'date']]\n",
    "        chunk = pd.merge(chunk, df, on='business_id') # merge business dataset and review dataset chunk\n",
    "        chunk_list.append(chunk)\n",
    "    df = pd.concat(chunk_list)\n",
    "    df.to_csv('Datasets/yelp dataset/yelp_dataset_merged.csv', index = False) # save dataset to CSV file\n",
    "    \n",
    "merge_datasets()\n",
    "df = pd.read_csv('Datasets/yelp dataset/yelp_dataset_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "handy-shepherd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 18254 \t user: 59 \t item:5134\n",
      " rating: 1    9682\n",
      "0    8572\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={'user_id':'user', 'business_id':'item', 'stars':'rating'})\n",
    "#df = df[(df.groupby('user')['user'].transform('size') > 10) & (df.groupby('item')['item'].transform('size') > 10)]\n",
    "df = df[(df.groupby('user')['user'].transform('size') > 200)]\n",
    "df['rating'] = df['rating'].apply(lambda x: 1 if x > 3 else 0) # make rating binary\n",
    "df = df.drop(columns='city') # drop city column since we are using only Toronto\n",
    "df = df.dropna() # drop any row with NaN values\n",
    "\n",
    "#df = df.groupby('rating').apply(lambda x: x.sample(1000))\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f'row: {len(df)} \\t user: {df.user.nunique()} \\t item:{df.item.nunique()}')\n",
    "\n",
    "# make user and items id start from 0\n",
    "df.user = pd.factorize(df.user)[0]\n",
    "df.item = pd.factorize(df.item)[0]\n",
    "\n",
    "\n",
    "print(f' rating: {df.rating.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-anatomy",
   "metadata": {},
   "source": [
    "## Context features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "amino-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_from_date(date):\n",
    "    seasons = np.arange(12)\n",
    "    seasons = seasons.reshape(4, 3) # reshape to a 2D matrix\n",
    "    i, j = np.where(seasons == date.month - 1) # get row where month appears\n",
    "    return i[0] + 1 # 1 = winter, 2 = spring, 3 = summer, 4 = autumn\n",
    "\n",
    "def holiday_from_date(date):\n",
    "    us_holidays = holidays.Canada()\n",
    "    return date in us_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "introductory-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date']) # convert from string to datetime\n",
    "df['season'] = df['date'].map(season_from_date)\n",
    "df['weekday'] = df['date'].dt.dayofweek # get day of the week from date (0 to 6)\n",
    "df['weekend'] = (df['weekday'] == 6) | (df['weekday'] == 5) # if is weekend from week day\n",
    "df['holiday'] = df['date'].map(holiday_from_date) # get holiday in Canada from date\n",
    "df = df.drop(columns=['date']) \n",
    "context = 'season weekday weekend holiday'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-monaco",
   "metadata": {},
   "source": [
    "## Item Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-sound",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "tracked-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"attributes\"] = df[\"attributes\"].apply(lambda x : dict(eval(x))) # convert to dict\n",
    "df = df.join(pd.json_normalize(df.attributes)).drop('attributes', axis=1) # expand dictionaries to new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for c in df.columns:\n",
    "    print('-'*10 + c + '-'*10)\n",
    "    print(df[c].value_counts())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "banned-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = 'Caters RestaurantsAttire RestaurantsPriceRange2 HasTV NoiseLevel RestaurantsDelivery RestaurantsReservations GoodForKids RestaurantsTakeOut Alcohol OutdoorSeating RestaurantsGoodForGroups GoodForMeal Ambience'.split()\n",
    "df = df[['user', 'item', 'rating', 'categories'] + context + attributes]  # keep only some attributes\n",
    "df = df.replace(to_replace='None', value=np.nan) # replace None strings with NaN\n",
    "df = df.dropna() # Drop NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "judicial-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'GoodForMeal Ambience'.split(): # some attributes need to be expanded again\n",
    "    df[col] = df[col].apply(lambda x : dict(eval(x))) # convert to dict\n",
    "    df = df.join(pd.json_normalize(df[col])).drop(col, axis=1) # expand dictionaries to new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "confident-wright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>categories</th>\n",
       "      <th>season</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>Caters</th>\n",
       "      <th>RestaurantsAttire</th>\n",
       "      <th>...</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>romantic</th>\n",
       "      <th>intimate</th>\n",
       "      <th>classy</th>\n",
       "      <th>hipster</th>\n",
       "      <th>divey</th>\n",
       "      <th>touristy</th>\n",
       "      <th>trendy</th>\n",
       "      <th>upscale</th>\n",
       "      <th>casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pizza, Italian, Salad, Restaurants</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>u'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pizza, Italian, Salad, Restaurants</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>u'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pizza, Italian, Salad, Restaurants</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>u'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pizza, Italian, Salad, Restaurants</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>u'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pizza, Italian, Salad, Restaurants</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>u'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18242</th>\n",
       "      <td>38</td>\n",
       "      <td>5128</td>\n",
       "      <td>1</td>\n",
       "      <td>Seafood, Japanese, Restaurants, Sushi Bars</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>u'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>58</td>\n",
       "      <td>5131</td>\n",
       "      <td>0</td>\n",
       "      <td>Japanese, Korean, Restaurants, Sushi Bars</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18249</th>\n",
       "      <td>38</td>\n",
       "      <td>4646</td>\n",
       "      <td>1</td>\n",
       "      <td>Restaurants, Japanese, Asian Fusion</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>u'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18252</th>\n",
       "      <td>58</td>\n",
       "      <td>4871</td>\n",
       "      <td>1</td>\n",
       "      <td>Food, Smokehouse, American (Traditional), Barb...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>u'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18253</th>\n",
       "      <td>18</td>\n",
       "      <td>5133</td>\n",
       "      <td>1</td>\n",
       "      <td>Restaurants, Chinese, Food Court, Comfort Food</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>'casual'</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11079 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating                                         categories  \\\n",
       "0         0     0       1                 Pizza, Italian, Salad, Restaurants   \n",
       "1         1     0       1                 Pizza, Italian, Salad, Restaurants   \n",
       "2         2     0       1                 Pizza, Italian, Salad, Restaurants   \n",
       "3         3     0       1                 Pizza, Italian, Salad, Restaurants   \n",
       "4         4     0       1                 Pizza, Italian, Salad, Restaurants   \n",
       "...     ...   ...     ...                                                ...   \n",
       "18242    38  5128       1         Seafood, Japanese, Restaurants, Sushi Bars   \n",
       "18247    58  5131       0          Japanese, Korean, Restaurants, Sushi Bars   \n",
       "18249    38  4646       1                Restaurants, Japanese, Asian Fusion   \n",
       "18252    58  4871       1  Food, Smokehouse, American (Traditional), Barb...   \n",
       "18253    18  5133       1     Restaurants, Chinese, Food Court, Comfort Food   \n",
       "\n",
       "       season  weekday  weekend  holiday Caters RestaurantsAttire  ...  \\\n",
       "0           4        1    False    False   True         u'casual'  ...   \n",
       "1           4        2    False    False   True         u'casual'  ...   \n",
       "2           3        5     True    False   True         u'casual'  ...   \n",
       "3           3        1    False    False   True         u'casual'  ...   \n",
       "4           3        4    False    False   True         u'casual'  ...   \n",
       "...       ...      ...      ...      ...    ...               ...  ...   \n",
       "18242       3        1    False    False  False         u'casual'  ...   \n",
       "18247       2        3    False    False   True          'casual'  ...   \n",
       "18249       2        6     True    False  False         u'casual'  ...   \n",
       "18252       3        5     True    False  False         u'casual'  ...   \n",
       "18253       4        0    False    False   True          'casual'  ...   \n",
       "\n",
       "      breakfast romantic intimate classy hipster  divey touristy trendy  \\\n",
       "0         False    False    False  False   False  False    False  False   \n",
       "1         False    False    False  False   False  False    False  False   \n",
       "2         False    False    False  False   False  False    False  False   \n",
       "3         False    False    False  False   False  False    False  False   \n",
       "4         False    False    False  False   False  False    False  False   \n",
       "...         ...      ...      ...    ...     ...    ...      ...    ...   \n",
       "18242     False    False    False  False   False  False    False  False   \n",
       "18247     False    False    False  False   False  False    False  False   \n",
       "18249     False    False    False  False   False  False    False  False   \n",
       "18252     False    False    False  False   False  False    False  False   \n",
       "18253     False    False    False  False   False  False    False  False   \n",
       "\n",
       "      upscale casual  \n",
       "0       False   True  \n",
       "1       False   True  \n",
       "2       False   True  \n",
       "3       False   True  \n",
       "4       False   True  \n",
       "...       ...    ...  \n",
       "18242   False  False  \n",
       "18247   False  False  \n",
       "18249   False  False  \n",
       "18252   False  False  \n",
       "18253   False  False  \n",
       "\n",
       "[11079 rows x 35 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(to_replace='None', value=False) # replace None with False\n",
    "df = df.fillna(False) # replace NaN with False\n",
    "df = df.dropna() # Drop NaN value\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-africa",
   "metadata": {},
   "source": [
    "## User features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "continent-concentrate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 246.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 205.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 225.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 200.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 179.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 217.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 202.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 225.13it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_user_feature_by_rating(df, column):\n",
    "    fav_values = np.zeros((df.user.nunique(), 2), dtype=object)\n",
    "    for user in tqdm(df.user.unique()):\n",
    "        # group by column unique values and sum ratings\n",
    "        grouped = df[['user', column, 'rating']][df.user == user].groupby(['user', column]).sum().sort_values('rating')\n",
    "        fav_val = grouped.tail(1).index.get_level_values(1).tolist()[0] # get value with highest rating sum\n",
    "        fav_values[user,:] = [user, fav_val] # add to numpy array of (user, fav_val)\n",
    "    return pd.DataFrame(fav_values, columns=['user', 'user_'+column]) # numpy to dataframe\n",
    "\n",
    "\n",
    "df = pd.merge(df, get_user_feature_by_rating(df, 'RestaurantsPriceRange2'), on=['user'])\n",
    "df = pd.merge(df, get_user_feature_by_rating(df, 'Alcohol'), on=['user'])\n",
    "df = pd.merge(df, get_user_feature_by_rating(df, 'RestaurantsDelivery'), on=['user'])\n",
    "df = pd.merge(df, get_user_feature_by_rating(df, 'RestaurantsReservations'), on=['user'])\n",
    "df = pd.merge(df, get_user_feature_by_rating(df, 'GoodForKids'), on=['user'])\n",
    "df = pd.merge(df, get_user_feature_by_rating(df, 'RestaurantsGoodForGroups'), on=['user'])\n",
    "df = pd.merge(df, get_user_feature_by_rating(df, 'NoiseLevel'), on=['user'])\n",
    "df = pd.merge(df, get_user_feature_by_rating(df, 'weekday'), on=['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "sporting-committee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caters', 'RestaurantsAttire', 'RestaurantsPriceRange2', 'HasTV', 'NoiseLevel', 'RestaurantsDelivery', 'RestaurantsReservations', 'GoodForKids', 'RestaurantsTakeOut', 'Alcohol', 'OutdoorSeating', 'RestaurantsGoodForGroups', 'dessert', 'latenight', 'lunch', 'dinner', 'brunch', 'breakfast', 'romantic', 'intimate', 'classy', 'hipster', 'divey', 'touristy', 'trendy', 'upscale', 'casual']\n",
      "\n",
      "['user_RestaurantsPriceRange2', 'user_Alcohol', 'user_RestaurantsDelivery', 'user_RestaurantsReservations', 'user_GoodForKids', 'user_RestaurantsGoodForGroups', 'user_NoiseLevel', 'user_weekday']\n"
     ]
    }
   ],
   "source": [
    "attributes = df.columns[8:-8].to_list()\n",
    "user_features = df.columns[-8:].to_list()\n",
    "print(attributes)\n",
    "print()\n",
    "print(user_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-liver",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "integrated-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode only context and attributes to preserve columns ordering\n",
    "df = pd.get_dummies(df, columns=context+attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "funded-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add categories\n",
    "df_categories = pd.Series(df['categories']).str.get_dummies(',')\n",
    "df = pd.concat([df, df_categories], axis=1)\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "boring-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the end one-hot encode user features\n",
    "df = pd.get_dummies(df, columns=user_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-adoption",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "selective-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.user = pd.factorize(df.user)[0]\n",
    "df.item = pd.factorize(df.item)[0]\n",
    "df.to_csv('Datasets/yelp dataset/yelp_final.csv', index = False) \n",
    "df = df.drop_duplicates(subset=['user', 'item']) # drop duplicates for matrix factorization\n",
    "df = df[['user', 'item', 'rating']]\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv('Datasets/yelp dataset/yelp_matrix_factorization.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
