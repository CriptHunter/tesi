{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "declared-underwear",
   "metadata": {},
   "source": [
    "# MDF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import holidays\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-finish",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nan_category(df):\n",
    "    \"\"\"\n",
    "    System apps like camera and gallery have NaN category, and different name for the same app (ex. samsung camera and huawei camera)\n",
    "    This function fix the category and assign a common name to system apps\n",
    "    \"\"\"\n",
    "    df.loc[df['app'].str.contains('camera'), 'category'] = 'PHOTOGRAPHY' # change category from NaN\n",
    "    df.loc[df['app'].str.contains('camera'), 'app'] = 'camera'  # change app name, all camera apps from various brands are equivalent\n",
    "    \n",
    "    df.loc[df['app'].str.contains('com.android.incallui'), 'category'] = 'COMMUNICATION' # incallui is the interface during a call\n",
    "    \n",
    "    df.loc[df['app'].str.contains('mail'), 'category'] = 'PRODUCTIVITY'\n",
    "    df.loc[df['app'].str.contains('com.google.android.gm'), 'category'] = 'PRODUCTIVITY' # change gmail category from communication to productivity\n",
    "    \n",
    "    df.loc[df['app'].str.contains('gallery'), 'category'] = 'PHOTOGRAPHY' # change category from NaN\n",
    "    df.loc[df['app'].str.contains('gallery'), 'app'] = 'gallery'  # change app name, all gallery apps from various brands are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wifi_scans(folder_path):\n",
    "    \"\"\"\n",
    "    Opens wifi_scans.csv file\n",
    "    group by time and assign true to a group only if there is at least one row with connected == true\n",
    "    skips the process if the file wifi_scans2.csv already exists\n",
    "    \"\"\"\n",
    "    if os.path.isfile(folder_path+'/wifi_scans2.csv'):\n",
    "        return\n",
    "    a = pd.read_csv(folder_path+'/wifi_scans.csv')\n",
    "    b = a[['time', 'connected']].groupby(['time'], as_index=False).any() # any() returns true if at least one entry is true\n",
    "    b.to_csv(folder_path+'/wifi_scans2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_row(file_path, columns, dt):\n",
    "    \"\"\"\n",
    "    finds the row in a dataframe whose time column is closest to dt\n",
    "\n",
    "    :file_path: CSV file location on disk\n",
    "    :columns: columns to read when opening the file\n",
    "    :dt: time in ms\n",
    "    :return: closest row as numpy array\n",
    "    \"\"\" \n",
    "    df = pd.read_csv(file_path, header=0, usecols=['time']+columns) # read only selected CSV columns + time column\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms') # convert from ms to date\n",
    "    df.sort_values('time', inplace=True)\n",
    "    df.drop_duplicates(subset='time', keep=\"first\", inplace=True)\n",
    "    df.set_index('time', inplace=True)\n",
    "    closest = df.iloc[[df.index.get_loc(dt, method='nearest')]].values[0] # find nearest row to time dt\n",
    "    return np.asarray(closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary structured as file : columns\n",
    "file_dict = {'activities.csv': ['in_vehicle', 'on_bicycle', 'on_foot', 'running', 'still', 'tilting', 'walking', 'unknown'], \n",
    "             'audio.csv': ['ringer_mode', 'alarm_volume', 'music_volume', 'notifications_volume', 'ring_volume', 'music_active', 'speaker_on', 'headset_connected'],\n",
    "             'battery.csv': ['level', 'charging'],\n",
    "             'display.csv': ['state', 'rotation'],\n",
    "             'weather.csv': ['temp', 'humidity', 'pressure', 'wind_speed', 'wind_deg',  'clouds', 'rain_last3h'],\n",
    "             'wifi_scans2.csv': ['connected'],\n",
    "             'location.csv': ['label', 'place_type']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Datasets/MDF/'\n",
    "# system apps like launcher,package manager, settings, ota...\n",
    "ignored_apps = \"\"\"it.cnr.iit.sensapp com.android.systemui com.sec.android.app.launcher com.android.settings com.android.vending\n",
    "                  com.android.captiveportallogin com.google.android.packageinstaller com.teslacoilsw.launcher com.android.packageinstaller\n",
    "                  com.samsung.android.MtpApplication com.sec.android.emergencylauncher com.wssyncmldm com.huawei.android.launcher\n",
    "                  com.huawei.systemmanager com.asus.launcher android com.asus.ime com.asus.dm com.cyanogenmod.trebuchet\n",
    "                  org.cyanogenmod.resolver com.android.launcher3 com.oneplus.ota com.samsung.android.game.gametools\n",
    "                  com.samsung.android.app.galaxyfinder com.huawei.gamebox.global com.sec.android.inputmethod com.android.phone \n",
    "                  com.samsung.android.scloud com.huawei.android.internal.app com.miui.home com.android.providers.downloads.ui\n",
    "                  com.android.printspooler com.lge.launcher3 com.lge.phonemanagement com.lge.bluetoothsetting com.lge.wifisettings\n",
    "                  com.lge.homeselector com.lge.launcher2 com.lge.lockscreensettings it.cnr.iit.contextlabeler\n",
    "                  com.sec.android.preloadinstaller com.android.server.telecom com.asus.powersaver com.android.stk\n",
    "                  it.cnr.iit.mymoviedb \"\"\".split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in range(31): # foreach user folder\n",
    "    user_dir = data_path + 'user_' + str(user)\n",
    "    filter_wifi_scans(user_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is one NaN value in time column of display.csv of user 27\n",
    "# it is the only exception in the whole dataset and if it not fixed it breaks the next cell\n",
    "df = pd.read_csv('Datasets/MDF/user_27/display.csv')\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv('Datasets/MDF/user_27/display.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()   \n",
    "for user in range(31): # foreach user folder\n",
    "    print(f\"working on user {user}...\")\n",
    "    user_dir = data_path + 'user_' + str(user)\n",
    "    \n",
    "    df1 = pd.read_csv(user_dir + '/running_apps.csv', header=0) # read running apps dataframe and use it as a starting point\n",
    "    df1 = df1[~df1['app'].isin(ignored_apps)]  # ignore system apps\n",
    "    fix_nan_category(df1)  # fix gallery, camera...\n",
    "    df1 = df1[~df1.app.str.contains(\"samsung|huawei|lge|asus|xiaomi|cyanogenmod\")] # ignore brand apps\n",
    "    df1 = df1[~df1.category.isnull()]  # ignore apps with NaN category\n",
    "    df1['time'] = pd.to_datetime(df1['time'], unit='ms') # convert date from ms to datetime\n",
    "    df1.sort_values('time', inplace=True)\n",
    "    # df1.drop_duplicates(subset='time', keep=\"first\", inplace=True) # drop time duplicate\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    df1.insert(1,'user',user) # insert user ID column\n",
    "    \n",
    "    rows = []\n",
    "    for dt in tqdm(df1['time']): # foreach row in running apps dataframe find the closest row in all other dataframes using datetime\n",
    "        row = []\n",
    "        for filename, columns in file_dict.items(): # foreach csv file in user folder\n",
    "            file_path = user_dir + '/' + filename\n",
    "            row = row + get_closest_row(file_path, columns, dt).tolist() # single row with all the context features\n",
    "        rows.append(row)\n",
    "\n",
    "    df2 = pd.DataFrame(rows, columns=np.concatenate(list(file_dict.values()))) # from list of list to dataframe\n",
    "    df3 = pd.concat([df1, df2], axis=1) # concat by column\n",
    "    df = pd.concat([df, df3], axis=0) # concat by row\n",
    "    \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"done!\")\n",
    "df.to_csv('Datasets/MDF_not_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/MDF_not_encoded.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-recycling",
   "metadata": {},
   "source": [
    "## Extract new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daytime_from_date(date):\n",
    "    hour = date.hour\n",
    "    if hour >= 5 and hour <= 12:\n",
    "        return 'morning'\n",
    "    elif hour >= 13 and hour <= 18:\n",
    "        return 'afternoon'\n",
    "    elif hour >= 19 and hour <= 22:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "    \n",
    "def weekday_from_date(date):\n",
    "    return date.strftime(\"%A\")\n",
    "\n",
    "def is_weekend(weekday:str):\n",
    "    return True if weekday == 'Saturday' or weekday == 'Sunday' else False\n",
    "\n",
    "it_holidays = holidays.Italy()\n",
    "\n",
    "def is_holiday(date):\n",
    "    return date in it_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daytime'] = df['time'].apply(daytime_from_date)\n",
    "df['weekday'] = df['time'].apply(weekday_from_date)\n",
    "df['is_weekend'] = df['weekday'].apply(is_weekend)\n",
    "df['is_holiday'] = df['time'].apply(is_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-buffer",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "### Fix labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-subscriber",
   "metadata": {},
   "source": [
    "**place type**: group similar labels under a more general labels (es. food, restaurant and bar under food label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['place_type'].isin(['restaurant', 'bar', 'cafe', 'food']), 'place_type'] = 'food_and_drink'\n",
    "df.loc[df['place_type'].isin(['route', 'street', 'park', 'tourist_attraction']), 'place_type'] = 'outdoors'\n",
    "df.loc[df['place_type'].isin(['transit_station', 'bus_station', 'taxi_stand']), 'place_type'] = 'public_transport_station'\n",
    "df.loc[df['place_type'].isin(['supermarket', 'home_goods', 'bakery', 'shopping_mall', 'library', 'book_store', 'florist']), 'place_type'] = 'store'\n",
    "df.loc[df['place_type'].isin(['health', 'doctor']), 'place_type'] = 'health'\n",
    "df.loc[df['place_type'].isin(['finance', 'gas_station', 'general_contractor', 'bank', 'premise', 'lawyer', 'insurance_agency', 'hair_care', 'city_hall', 'plumber', 'pharmacy', 'police', 'veterinary', 'laundry', 'place_of_worship', 'university', 'moving_company', 'post_office', 'car_repair', 'real_estate_agency', 'painter', 'car_wash', 'local_government_office', 'beauty_salon', 'electrician', 'car_rental', 'funeral_home', 'fire_station', 'travel_agency']), 'place_type'] = 'service'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-documentation",
   "metadata": {},
   "source": [
    "**category**: group all GAME subcategories under GAME label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category'].str.contains('GAME'), 'category'] = 'GAME'\n",
    "df.loc[df['category'].isin([' COMMUNICATION']), 'category'] = 'COMMUNICATION' # fix communication category with space at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-alpha",
   "metadata": {},
   "source": [
    "### App\n",
    "Convert **app** from package name to unique IDs and rename to item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.app = pd.factorize(df.app)[0]\n",
    "df = df.rename(columns={'app': 'item'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-warehouse",
   "metadata": {},
   "source": [
    "### Category\n",
    "**Category** is one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['category'], prefix='category')), axis=1)\n",
    "df.pop('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-completion",
   "metadata": {},
   "source": [
    "### Activities\n",
    "**in_vehicle, on_bicycle, on_foot, running, still, tilting, walking, unknown** represent the probability from 0 to 100 that the user is doing an activity. These features are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = 'in_vehicle on_bicycle on_foot running still tilting walking unknown'.split()\n",
    "df[activities] = df[activities].apply(lambda x: x/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-bottom",
   "metadata": {},
   "source": [
    "### Volume\n",
    "- **ringer_mode** is one hot encoded\n",
    "- **alarm_volume, music_volume, notifications_volume, ring_volume, music_active, speaker_on, headset_connected** are already normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['ringer_mode'], prefix='ringer_mode')), axis=1)\n",
    "df.pop('ringer_mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-preliminary",
   "metadata": {},
   "source": [
    "### Battery\n",
    "- Battery **level** goes from 0 to 1, where 1 is full charged, it is converted to a categorical variable and then one-hot encoded\n",
    "- **charging** is boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_battery_status(lv):\n",
    "    lv = lv * 100\n",
    "    if lv >= 80:\n",
    "        return 'charged'\n",
    "    elif lv >= 60 and lv < 80:\n",
    "        return 'quite charged'\n",
    "    elif lv >= 40 and lv < 60:\n",
    "        return 'half charged'\n",
    "    elif lv >= 20 and lv < 40:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'very low'\n",
    "\n",
    "df['level'] = df['level'].apply(get_battery_status)\n",
    "df = pd.concat((df, pd.get_dummies(df['level'], prefix='battery')), axis=1)\n",
    "df.pop('level')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-adult",
   "metadata": {},
   "source": [
    "### Display\n",
    "- **state** can be 1,2,3,4\n",
    "- **rotation** can be 0,1,3\n",
    "\n",
    "Both variables are one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['state'], prefix='display_state')), axis=1)\n",
    "df = pd.concat((df, pd.get_dummies(df['rotation'], prefix='display_rotation')), axis=1)\n",
    "df.pop('state')\n",
    "df.pop('rotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-facial",
   "metadata": {},
   "source": [
    "### Weather\n",
    "- **temp**, **humidity, pressure, wind_speed, wind_deg**, **clouds** are normalized\n",
    "- **rain_last3h** is transformed into a boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rain_last3h'] = df['rain_last3h'].apply(lambda x: 1 if x > 0 else 0) # true if it rained\n",
    "\n",
    "cols_to_norm = 'temp humidity pressure wind_speed wind_deg clouds'.split()\n",
    "df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-construction",
   "metadata": {},
   "source": [
    "### Place and date\n",
    "**place_type, daytime, weekday** are one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'place_type daytime weekday'.split()\n",
    "for e in cols:\n",
    "    df = pd.concat((df, pd.get_dummies(df[e], prefix=e)), axis=1)\n",
    "    df.pop(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-arbitration",
   "metadata": {},
   "source": [
    "### Boolean to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'music_active speaker_on headset_connected connected is_weekend is_holiday'.split():\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-combining",
   "metadata": {},
   "source": [
    "### Add rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.pop('time')\n",
    "df['rating'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-mayor",
   "metadata": {},
   "source": [
    "## Dataset for matrix factorization\n",
    "MF requires a dataset with only positive interaction and where a tuple (user, item) is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf = pd.DataFrame(df[['user', 'item', 'rating']])\n",
    "df_mf.drop_duplicates(inplace=True)\n",
    "df_mf.user = pd.factorize(df_mf.user)[0]\n",
    "df_mf.item = pd.factorize(df_mf.item)[0]\n",
    "df_mf.to_csv('Datasets/MDF_matrix_factorization.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-essay",
   "metadata": {},
   "source": [
    "## Negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "all_labels = df.label.unique() # all possible context of a single user\n",
    "\n",
    "items_labels = {} # dictionary that contains in which contexts an item has been used\n",
    "for item in df.item.unique():\n",
    "    items_labels[item] = df[df.item == item]['label'].unique()\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    item = row['item']\n",
    "    pos_labels = items_labels[item]  # contexts in which an item has been used\n",
    "    neg_labels = list(set(all_labels) - set(pos_labels))  # contexts in which an item has NOT been used\n",
    "    for neg in neg_labels: # generate a new negative sample foreach negative label\n",
    "        neg_context = df.loc[(df.item != item) & (df.label == neg)].sample(n=1) # take a random item with negative context\n",
    "        neg_context = neg_context.iloc[:, 4:] # keep only the context\n",
    "        item_row = pd.DataFrame(row.iloc[0:4]).transpose() # take user, item, rating\n",
    "        item_row.reset_index(drop=True, inplace=True) # reset index for concat\n",
    "        neg_context.reset_index(drop=True, inplace=True)\n",
    "        neg_row = pd.concat([item_row, neg_context], axis=1)\n",
    "        neg_row.rating = 0\n",
    "        neg_df = neg_df.append(neg_row)   \n",
    "\n",
    "df = df.append(neg_df)\n",
    "df.sort_values(by=['user'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = df.pop('rating')\n",
    "df.insert(2, rating.name, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-refrigerator",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/MDF_final_timestamp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
