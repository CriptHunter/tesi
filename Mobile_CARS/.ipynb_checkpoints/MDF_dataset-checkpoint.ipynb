{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solved-russia",
   "metadata": {},
   "source": [
    "# MDF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import holidays\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-cooper",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nan_category(df):\n",
    "    df.loc[df['app'].str.contains('camera'), 'category'] = 'PHOTOGRAPHY' # change category from NaN\n",
    "    df.loc[df['app'].str.contains('camera'), 'app'] = 'camera'  # change app name, all camera apps from various brands are equivalent\n",
    "    \n",
    "    df.loc[df['app'].str.contains('com.android.incallui'), 'category'] = 'COMMUNICATION' # incallui is the interface during a call\n",
    "    \n",
    "    df.loc[df['app'].str.contains('mail'), 'category'] = 'PRODUCTIVITY'\n",
    "    df.loc[df['app'].str.contains('com.google.android.gm'), 'category'] = 'PRODUCTIVITY' # change gmail category from communication to productivity\n",
    "    \n",
    "    df.loc[df['app'].str.contains('gallery'), 'category'] = 'PHOTOGRAPHY' # change category from NaN\n",
    "    df.loc[df['app'].str.contains('gallery'), 'app'] = 'gallery'  # change app name, all gallery apps from various brands are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wifi_scans(folder_path):\n",
    "    \"\"\"\n",
    "    Opens wifi_scans.csv file\n",
    "    group by time and assign true to a group only if there is at least one row with connected == true\n",
    "    skips the process if the file wifi_scans2.csv already exists\n",
    "    \"\"\"\n",
    "    if os.path.isfile(folder_path+'/wifi_scans2.csv'):\n",
    "        # print (f\"File {folder_path+'/wifi_scans2.csv'} already exists\")\n",
    "        return\n",
    "    a = pd.read_csv(folder_path+'/wifi_scans.csv')\n",
    "    b = a[['time', 'connected']].groupby(['time'], as_index=False).any() # any() returns true if at least one entry is true\n",
    "    b.to_csv(folder_path+'/wifi_scans2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_row(file_path, columns, dt):\n",
    "    \"\"\"\n",
    "    finds the row in a dataframe whose time column is closest to dt\n",
    "\n",
    "    :file_path: CSV file location on disk\n",
    "    :columns: columns to read when opening the file\n",
    "    :dt: time in ms\n",
    "    :return: closest row as numpy array\n",
    "    \"\"\" \n",
    "    df = pd.read_csv(file_path, header=0, usecols=['time']+columns) # read only selected CSV columns + time column\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms') # convert from ms to date\n",
    "    df.sort_values('time', inplace=True)\n",
    "    df.drop_duplicates(subset='time', keep=\"first\", inplace=True)\n",
    "    df.set_index('time', inplace=True)\n",
    "    closest = df.iloc[[df.index.get_loc(dt, method='nearest')]].values[0] # find nearest row to time dt\n",
    "    return np.asarray(closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary structured as file : columns\n",
    "file_dict = {'activities.csv': ['in_vehicle', 'on_bicycle', 'on_foot', 'running', 'still', 'tilting', 'walking', 'unknown'], \n",
    "             'audio.csv': ['ringer_mode', 'alarm_volume', 'music_volume', 'notifications_volume', 'ring_volume', 'music_active', 'speaker_on', 'headset_connected'],\n",
    "             'battery.csv': ['level', 'charging'],\n",
    "             'display.csv': ['state', 'rotation'],\n",
    "             'weather.csv': ['temp', 'humidity', 'pressure', 'wind_speed', 'wind_deg',  'clouds', 'rain_last3h'],\n",
    "             'wifi_scans2.csv': ['connected'],\n",
    "             'location.csv': ['label', 'place_type']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Datasets/MDF/'\n",
    "# system apps like launcher,package manager, settings, ota...\n",
    "ignored_apps = \"\"\"it.cnr.iit.sensapp com.android.systemui com.sec.android.app.launcher com.android.settings com.android.vending\n",
    "                  com.android.captiveportallogin com.google.android.packageinstaller com.teslacoilsw.launcher com.android.packageinstaller\n",
    "                  com.samsung.android.MtpApplication com.sec.android.emergencylauncher com.wssyncmldm com.huawei.android.launcher\n",
    "                  com.huawei.systemmanager com.asus.launcher android com.asus.ime com.asus.dm com.cyanogenmod.trebuchet\n",
    "                  org.cyanogenmod.resolver com.android.launcher3 com.oneplus.ota com.samsung.android.game.gametools\n",
    "                  com.samsung.android.app.galaxyfinder com.huawei.gamebox.global com.sec.android.inputmethod com.android.phone \n",
    "                  com.samsung.android.scloud com.huawei.android.internal.app com.miui.home com.android.providers.downloads.ui\n",
    "                  com.android.printspooler com.lge.launcher3 com.lge.phonemanagement com.lge.bluetoothsetting com.lge.wifisettings\n",
    "                  com.lge.homeselector com.lge.launcher2 com.lge.lockscreensettings it.cnr.iit.contextlabeler\n",
    "                  com.sec.android.preloadinstaller com.android.server.telecom com.asus.powersaver com.android.stk\n",
    "                  it.cnr.iit.mymoviedb \"\"\".split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in range(31): # foreach user folder\n",
    "    user_dir = data_path + 'user_' + str(user)\n",
    "    filter_wifi_scans(user_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()   \n",
    "for user in list(range(0,27)) + list(range(28,31)): # foreach user folder, skip user 27 it doesn't works for some reasons\n",
    "    print(f\"working on user {user}...\")\n",
    "    user_dir = data_path + 'user_' + str(user)\n",
    "    \n",
    "    df1 = pd.read_csv(user_dir + '/running_apps.csv', header=0) # read running apps dataframe and use it as a starting point\n",
    "    df1 = df1[~df1['app'].isin(ignored_apps)]  # ignore system apps\n",
    "    fix_nan_category(df1)\n",
    "    df1 = df1[~df1.app.str.contains(\"samsung|huawei|lge|asus|xiaomi|cyanogenmod\")] # ignore brand apps\n",
    "    df1 = df1[~df1.category.isnull()]  # ignore apps with NaN category\n",
    "    df1['time'] = pd.to_datetime(df1['time'], unit='ms') # convert date from ms to datetime\n",
    "    df1.sort_values('time', inplace=True)\n",
    "    df1.drop_duplicates(subset='time', keep=\"first\", inplace=True)\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    df1.insert(1,'user',user) # insert user ID column\n",
    "    \n",
    "    rows = []\n",
    "    for dt in tqdm(df1['time']): # foreach row in running apps dataframe find the closest row in all other dataframes using datetime\n",
    "        row = []\n",
    "        for filename, columns in file_dict.items(): # foreach csv file in user folder\n",
    "            file_path = user_dir + '/' + filename\n",
    "            row = row + get_closest_row(file_path, columns, dt).tolist() # single row with all the context features\n",
    "        rows.append(row)\n",
    "\n",
    "    df2 = pd.DataFrame(rows, columns=np.concatenate(list(file_dict.values()))) # from list of list to dataframe\n",
    "    df3 = pd.concat([df1, df2], axis=1) # concat by column\n",
    "    df = pd.concat([df, df3], axis=0) # concat by row\n",
    "    \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-control",
   "metadata": {},
   "source": [
    "## Extract new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daytime_from_date(date):\n",
    "    hour = date.hour\n",
    "    if hour >= 5 and hour <= 12:\n",
    "        return 'morning'\n",
    "    elif hour >= 13 and hour <= 18:\n",
    "        return 'afternoon'\n",
    "    elif hour >= 19 and hour <= 22:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "    \n",
    "def weekday_from_date(date):\n",
    "    return date.strftime(\"%A\")\n",
    "\n",
    "def is_weekend(weekday:str):\n",
    "    return True if weekday == 'Saturday' or weekday == 'Sunday' else False\n",
    "\n",
    "it_holidays = holidays.Italy()\n",
    "\n",
    "def is_holiday(date):\n",
    "    return date in it_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daytime'] = df['time'].apply(daytime_from_date)\n",
    "df['weekday'] = df['time'].apply(weekday_from_date)\n",
    "df['is_weekend'] = df['weekday'].apply(is_weekend)\n",
    "df['is_holiday'] = df['time'].apply(is_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-foundation",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "### Fix labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-metropolitan",
   "metadata": {},
   "source": [
    "**place type**: group similar labels under a more general labels (es. food, restaurant and bar under food label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['place_type'].isin(['restaurant', 'bar', 'cafe', 'food']), 'place_type'] = 'food_and_drink'\n",
    "df.loc[df['place_type'].isin(['route', 'street', 'park', 'tourist_attraction']), 'place_type'] = 'outdoors'\n",
    "df.loc[df['place_type'].isin(['transit_station', 'bus_station', 'taxi_stand']), 'place_type'] = 'public_transport_station'\n",
    "df.loc[df['place_type'].isin(['supermarket', 'home_goods', 'bakery', 'shopping_mall', 'library', 'book_store', 'florist']), 'place_type'] = 'store'\n",
    "df.loc[df['place_type'].isin(['health', 'doctor']), 'place_type'] = 'health'\n",
    "df.loc[df['place_type'].isin(['finance', 'gas_station', 'general_contractor', 'bank', 'premise', 'lawyer', 'insurance_agency', 'hair_care', 'city_hall', 'plumber', 'pharmacy', 'police', 'veterinary', 'laundry', 'place_of_worship', 'university', 'moving_company', 'post_office', 'car_repair', 'real_estate_agency', 'painter', 'car_wash', 'local_government_office', 'beauty_salon', 'electrician', 'car_rental', 'funeral_home', 'fire_station', 'travel_agency']), 'place_type'] = 'service'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-makeup",
   "metadata": {},
   "source": [
    "**category**: group all GAME subcategories under GAME label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category'].str.contains('GAME'), 'category'] = 'GAME'\n",
    "df.loc[df['category'].isin([' COMMUNICATION']), 'category'] = 'COMMUNICATION' # fix communication category with space at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-arrest",
   "metadata": {},
   "source": [
    "### App\n",
    "Convert **app** from package name to unique IDs and rename to item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.app = pd.factorize(df.app)[0]\n",
    "df = df.rename(columns={'app': 'item'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-narrow",
   "metadata": {},
   "source": [
    "### Activities\n",
    "**in_vehicle, on_bicycle, on_foot, running, still, tilting, walking, unknown** represent the probability from 0 to 100 that the user is doing that activity. We normalize these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = 'in_vehicle on_bicycle on_foot running still tilting walking unknown'.split()\n",
    "df[activities] = df[activities].apply(lambda x: x/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-toilet",
   "metadata": {},
   "source": [
    "### Battery\n",
    "Battery **level** goes from 0 to 1, where 1 is full charged, we encode it as a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_battery_status(lv):\n",
    "    lv = lv * 100\n",
    "    if lv >= 80:\n",
    "        return 'charged'\n",
    "    elif lv >= 60 and lv < 80:\n",
    "        return 'quite charged'\n",
    "    elif lv >= 40 and lv < 60:\n",
    "        return 'half charged'\n",
    "    elif lv >= 20 and lv < 40:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'very low'\n",
    "\n",
    "df['level'] = df['level'].apply(get_battery_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-effort",
   "metadata": {},
   "source": [
    "### Weather\n",
    "- Temperature **temp** is encoded as a categorical variable\n",
    "- **humidity, pressure, wind_speed, wind_deg** are normalized\n",
    "- **clouds**, **rain_last3h** ---> sono valori numerici quindi boh ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temperature(degree):\n",
    "    if degree <= 5:\n",
    "        return 'very_cold'\n",
    "    elif degree > 5 and degree <= 10:\n",
    "        return 'cold'\n",
    "    elif degree > 10 and degree <= 15:\n",
    "        return 'coldish'\n",
    "    elif degree > 15 and degree <= 20:\n",
    "        return 'warm'\n",
    "    elif degree > 20 and degree <= 30:\n",
    "        return 'hot'\n",
    "    else:\n",
    "        return 'very_hot'\n",
    "        \n",
    "df['temp'] = df['temp'].apply(get_temperature)\n",
    "df = pd.concat((df, pd.get_dummies(df['temp'], prefix='temp')), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-racing",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rain_last3h.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['place_type'].value_counts().plot.bar(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts().plot.bar(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts().plot.bar(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-gnome",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('MDF_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
