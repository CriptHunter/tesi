{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dress-bosnia",
   "metadata": {},
   "source": [
    "# MDF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proved-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import holidays\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-nashville",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nan_category(df):\n",
    "    \"\"\"\n",
    "    System apps like camera and gallery have NaN category, and different name for the same app (ex. samsung camera and huawei camera)\n",
    "    This function fix the category and assign a common name to system apps\n",
    "    \"\"\"\n",
    "    df.loc[df['app'].str.contains('camera'), 'category'] = 'PHOTOGRAPHY' # change category from NaN\n",
    "    df.loc[df['app'].str.contains('camera'), 'app'] = 'camera'  # change app name, all camera apps from various brands are equivalent\n",
    "    \n",
    "    df.loc[df['app'].str.contains('com.android.incallui'), 'category'] = 'COMMUNICATION' # incallui is the interface during a call\n",
    "    \n",
    "    df.loc[df['app'].str.contains('mail'), 'category'] = 'PRODUCTIVITY'\n",
    "    df.loc[df['app'].str.contains('com.google.android.gm'), 'category'] = 'PRODUCTIVITY' # change gmail category from communication to productivity\n",
    "    \n",
    "    df.loc[df['app'].str.contains('gallery'), 'category'] = 'PHOTOGRAPHY' # change category from NaN\n",
    "    df.loc[df['app'].str.contains('gallery'), 'app'] = 'gallery'  # change app name, all gallery apps from various brands are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wifi_scans(folder_path):\n",
    "    \"\"\"\n",
    "    Opens wifi_scans.csv file\n",
    "    group by time and assign true to a group only if there is at least one row with connected == true\n",
    "    skips the process if the file wifi_scans2.csv already exists\n",
    "    \"\"\"\n",
    "    if os.path.isfile(folder_path+'/wifi_scans2.csv'):\n",
    "        return\n",
    "    a = pd.read_csv(folder_path+'/wifi_scans.csv')\n",
    "    b = a[['time', 'connected']].groupby(['time'], as_index=False).any() # any() returns true if at least one entry is true\n",
    "    b.to_csv(folder_path+'/wifi_scans2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_row(file_path, columns, dt):\n",
    "    \"\"\"\n",
    "    finds the row in a dataframe whose time column is closest to dt\n",
    "\n",
    "    :file_path: CSV file location on disk\n",
    "    :columns: columns to read when opening the file\n",
    "    :dt: time in ms\n",
    "    :return: closest row as numpy array\n",
    "    \"\"\" \n",
    "    df = pd.read_csv(file_path, header=0, usecols=['time']+columns) # read only selected CSV columns + time column\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms') # convert from ms to date\n",
    "    df.sort_values('time', inplace=True)\n",
    "    df.drop_duplicates(subset='time', keep=\"first\", inplace=True)\n",
    "    df.set_index('time', inplace=True)\n",
    "    closest = df.iloc[[df.index.get_loc(dt, method='nearest')]].values[0] # find nearest row to time dt\n",
    "    return np.asarray(closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary structured as file : columns\n",
    "file_dict = {'activities.csv': ['in_vehicle', 'on_bicycle', 'on_foot', 'running', 'still', 'tilting', 'walking', 'unknown'], \n",
    "             'audio.csv': ['ringer_mode', 'alarm_volume', 'music_volume', 'notifications_volume', 'ring_volume', 'music_active', 'speaker_on', 'headset_connected'],\n",
    "             'battery.csv': ['level', 'charging'],\n",
    "             'display.csv': ['state', 'rotation'],\n",
    "             'weather.csv': ['temp', 'humidity', 'pressure', 'wind_speed', 'wind_deg',  'clouds', 'rain_last3h'],\n",
    "             'wifi_scans2.csv': ['connected'],\n",
    "             'location.csv': ['label', 'place_type']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Datasets/MDF/'\n",
    "# system apps like launcher,package manager, settings, ota...\n",
    "ignored_apps = \"\"\"it.cnr.iit.sensapp com.android.systemui com.sec.android.app.launcher com.android.settings com.android.vending\n",
    "                  com.android.captiveportallogin com.google.android.packageinstaller com.teslacoilsw.launcher com.android.packageinstaller\n",
    "                  com.samsung.android.MtpApplication com.sec.android.emergencylauncher com.wssyncmldm com.huawei.android.launcher\n",
    "                  com.huawei.systemmanager com.asus.launcher android com.asus.ime com.asus.dm com.cyanogenmod.trebuchet\n",
    "                  org.cyanogenmod.resolver com.android.launcher3 com.oneplus.ota com.samsung.android.game.gametools\n",
    "                  com.samsung.android.app.galaxyfinder com.huawei.gamebox.global com.sec.android.inputmethod com.android.phone \n",
    "                  com.samsung.android.scloud com.huawei.android.internal.app com.miui.home com.android.providers.downloads.ui\n",
    "                  com.android.printspooler com.lge.launcher3 com.lge.phonemanagement com.lge.bluetoothsetting com.lge.wifisettings\n",
    "                  com.lge.homeselector com.lge.launcher2 com.lge.lockscreensettings it.cnr.iit.contextlabeler\n",
    "                  com.sec.android.preloadinstaller com.android.server.telecom com.asus.powersaver com.android.stk\n",
    "                  it.cnr.iit.mymoviedb \"\"\".split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in range(31): # foreach user folder\n",
    "    user_dir = data_path + 'user_' + str(user)\n",
    "    filter_wifi_scans(user_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()   \n",
    "for user in list(range(0,27)) + list(range(28,31)): # foreach user folder, skip user 27 it doesn't works for some reasons\n",
    "    print(f\"working on user {user}...\")\n",
    "    user_dir = data_path + 'user_' + str(user)\n",
    "    \n",
    "    df1 = pd.read_csv(user_dir + '/running_apps.csv', header=0) # read running apps dataframe and use it as a starting point\n",
    "    df1 = df1[~df1['app'].isin(ignored_apps)]  # ignore system apps\n",
    "    fix_nan_category(df1)  # fix gallery, camera...\n",
    "    df1 = df1[~df1.app.str.contains(\"samsung|huawei|lge|asus|xiaomi|cyanogenmod\")] # ignore brand apps\n",
    "    df1 = df1[~df1.category.isnull()]  # ignore apps with NaN category\n",
    "    df1['time'] = pd.to_datetime(df1['time'], unit='ms') # convert date from ms to datetime\n",
    "    df1.sort_values('time', inplace=True)\n",
    "    # df1.drop_duplicates(subset='time', keep=\"first\", inplace=True) # drop time duplicate\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    df1.insert(1,'user',user) # insert user ID column\n",
    "    \n",
    "    rows = []\n",
    "    for dt in tqdm(df1['time']): # foreach row in running apps dataframe find the closest row in all other dataframes using datetime\n",
    "        row = []\n",
    "        for filename, columns in file_dict.items(): # foreach csv file in user folder\n",
    "            file_path = user_dir + '/' + filename\n",
    "            row = row + get_closest_row(file_path, columns, dt).tolist() # single row with all the context features\n",
    "        rows.append(row)\n",
    "\n",
    "    df2 = pd.DataFrame(rows, columns=np.concatenate(list(file_dict.values()))) # from list of list to dataframe\n",
    "    df3 = pd.concat([df1, df2], axis=1) # concat by column\n",
    "    df = pd.concat([df, df3], axis=0) # concat by row\n",
    "    \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"done!\")\n",
    "df.to_csv('MDF_not_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungry-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('MDF_not_encoded.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-electricity",
   "metadata": {},
   "source": [
    "## Extract new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "choice-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daytime_from_date(date):\n",
    "    hour = date.hour\n",
    "    if hour >= 5 and hour <= 12:\n",
    "        return 'morning'\n",
    "    elif hour >= 13 and hour <= 18:\n",
    "        return 'afternoon'\n",
    "    elif hour >= 19 and hour <= 22:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "    \n",
    "def weekday_from_date(date):\n",
    "    return date.strftime(\"%A\")\n",
    "\n",
    "def is_weekend(weekday:str):\n",
    "    return True if weekday == 'Saturday' or weekday == 'Sunday' else False\n",
    "\n",
    "it_holidays = holidays.Italy()\n",
    "\n",
    "def is_holiday(date):\n",
    "    return date in it_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "irish-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daytime'] = df['time'].apply(daytime_from_date)\n",
    "df['weekday'] = df['time'].apply(weekday_from_date)\n",
    "df['is_weekend'] = df['weekday'].apply(is_weekend)\n",
    "df['is_holiday'] = df['time'].apply(is_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-student",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "### Fix labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-ceiling",
   "metadata": {},
   "source": [
    "**place type**: group similar labels under a more general labels (es. food, restaurant and bar under food label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "crude-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['place_type'].isin(['restaurant', 'bar', 'cafe', 'food']), 'place_type'] = 'food_and_drink'\n",
    "df.loc[df['place_type'].isin(['route', 'street', 'park', 'tourist_attraction']), 'place_type'] = 'outdoors'\n",
    "df.loc[df['place_type'].isin(['transit_station', 'bus_station', 'taxi_stand']), 'place_type'] = 'public_transport_station'\n",
    "df.loc[df['place_type'].isin(['supermarket', 'home_goods', 'bakery', 'shopping_mall', 'library', 'book_store', 'florist']), 'place_type'] = 'store'\n",
    "df.loc[df['place_type'].isin(['health', 'doctor']), 'place_type'] = 'health'\n",
    "df.loc[df['place_type'].isin(['finance', 'gas_station', 'general_contractor', 'bank', 'premise', 'lawyer', 'insurance_agency', 'hair_care', 'city_hall', 'plumber', 'pharmacy', 'police', 'veterinary', 'laundry', 'place_of_worship', 'university', 'moving_company', 'post_office', 'car_repair', 'real_estate_agency', 'painter', 'car_wash', 'local_government_office', 'beauty_salon', 'electrician', 'car_rental', 'funeral_home', 'fire_station', 'travel_agency']), 'place_type'] = 'service'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-floating",
   "metadata": {},
   "source": [
    "**category**: group all GAME subcategories under GAME label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "upset-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category'].str.contains('GAME'), 'category'] = 'GAME'\n",
    "df.loc[df['category'].isin([' COMMUNICATION']), 'category'] = 'COMMUNICATION' # fix communication category with space at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-audit",
   "metadata": {},
   "source": [
    "### App\n",
    "Convert **app** from package name to unique IDs and rename to item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fantastic-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.app = pd.factorize(df.app)[0]\n",
    "df = df.rename(columns={'app': 'item'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-examination",
   "metadata": {},
   "source": [
    "### Category\n",
    "**Category** is one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "center-poker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             COMMUNICATION\n",
       "1        NEWS_AND_MAGAZINES\n",
       "2             COMMUNICATION\n",
       "3        NEWS_AND_MAGAZINES\n",
       "4             COMMUNICATION\n",
       "                ...        \n",
       "53013                SOCIAL\n",
       "53014         COMMUNICATION\n",
       "53015                SOCIAL\n",
       "53016         COMMUNICATION\n",
       "53017                SOCIAL\n",
       "Name: category, Length: 53018, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['category'], prefix='category')), axis=1)\n",
    "df.pop('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-craps",
   "metadata": {},
   "source": [
    "### Activities\n",
    "**in_vehicle, on_bicycle, on_foot, running, still, tilting, walking, unknown** represent the probability from 0 to 100 that the user is doing an activity. These features are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlikely-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = 'in_vehicle on_bicycle on_foot running still tilting walking unknown'.split()\n",
    "df[activities] = df[activities].apply(lambda x: x/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-wichita",
   "metadata": {},
   "source": [
    "### Volume\n",
    "- **ringer_mode** is one hot encoded\n",
    "- **alarm_volume, music_volume, notifications_volume, ring_volume, music_active, speaker_on, headset_connected** are already normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chemical-horse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "53013    2\n",
       "53014    2\n",
       "53015    2\n",
       "53016    2\n",
       "53017    2\n",
       "Name: ringer_mode, Length: 53018, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['ringer_mode'], prefix='ringer_mode')), axis=1)\n",
    "df.pop('ringer_mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-joint",
   "metadata": {},
   "source": [
    "### Battery\n",
    "- Battery **level** goes from 0 to 1, where 1 is full charged, it is converted to a categorical variable and then one-hot encoded\n",
    "- **charging** is boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "heard-performance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              charged\n",
       "1              charged\n",
       "2        quite charged\n",
       "3        quite charged\n",
       "4        quite charged\n",
       "             ...      \n",
       "53013     half charged\n",
       "53014     half charged\n",
       "53015     half charged\n",
       "53016     half charged\n",
       "53017              low\n",
       "Name: level, Length: 53018, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_battery_status(lv):\n",
    "    lv = lv * 100\n",
    "    if lv >= 80:\n",
    "        return 'charged'\n",
    "    elif lv >= 60 and lv < 80:\n",
    "        return 'quite charged'\n",
    "    elif lv >= 40 and lv < 60:\n",
    "        return 'half charged'\n",
    "    elif lv >= 20 and lv < 40:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'very low'\n",
    "\n",
    "df['level'] = df['level'].apply(get_battery_status)\n",
    "df = pd.concat((df, pd.get_dummies(df['level'], prefix='battery')), axis=1)\n",
    "df.pop('level')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-algebra",
   "metadata": {},
   "source": [
    "### Display\n",
    "- **state** can be 1,2,3,4\n",
    "- **rotation** can be 0,1,3\n",
    "\n",
    "Both variables are one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "static-strength",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "53013    0\n",
       "53014    0\n",
       "53015    0\n",
       "53016    0\n",
       "53017    0\n",
       "Name: rotation, Length: 53018, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['state'], prefix='display_state')), axis=1)\n",
    "df = pd.concat((df, pd.get_dummies(df['rotation'], prefix='display_rotation')), axis=1)\n",
    "df.pop('state')\n",
    "df.pop('rotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-roberts",
   "metadata": {},
   "source": [
    "### Weather\n",
    "- **temp**, **humidity, pressure, wind_speed, wind_deg**, **clouds** are normalized\n",
    "- **rain_last3h** is transformed into a boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nutritional-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rain_last3h'] = df['rain_last3h'].apply(lambda x: 1 if x > 0 else 0) # true if it rained\n",
    "\n",
    "cols_to_norm = 'temp humidity pressure wind_speed wind_deg clouds'.split()\n",
    "df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-surprise",
   "metadata": {},
   "source": [
    "### Place and date\n",
    "**place_type, daytime, weekday** are one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sapphire-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'place_type daytime weekday'.split()\n",
    "for e in cols:\n",
    "    df = pd.concat((df, pd.get_dummies(df[e], prefix=e)), axis=1)\n",
    "    df.pop(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-commission",
   "metadata": {},
   "source": [
    "### Boolean to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "million-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'music_active speaker_on headset_connected connected is_weekend is_holiday'.split():\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-equality",
   "metadata": {},
   "source": [
    "### Add rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daily-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop('time')\n",
    "df['rating'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-gateway",
   "metadata": {},
   "source": [
    "## Negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "all_labels = df.label.unique() # all possible context of a single user\n",
    "\n",
    "items_labels = {} # dictionary that contains in which contexts an item has been used\n",
    "for item in df.item.unique():\n",
    "    items_labels[item] = df[df.item == item]['label'].unique()\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    item = row['item']\n",
    "    pos_labels = items_labels[item]  # contexts in which an item has been used\n",
    "    neg_labels = list(set(all_labels) - set(pos_labels))  # contexts in which an item has NOT been used\n",
    "    for neg in neg_labels: # generate a new negative sample foreach negative label\n",
    "        neg_context = df.loc[(df.item != item) & (df.label == neg)].sample(n=1) # take a random item with negative context\n",
    "        neg_context = neg_context.iloc[:, 4:] # keep only the context\n",
    "        item_row = pd.DataFrame(row.iloc[0:4]).transpose() # take user, item, rating\n",
    "        item_row.reset_index(drop=True, inplace=True) # reset index for concat\n",
    "        neg_context.reset_index(drop=True, inplace=True)\n",
    "        neg_row = pd.concat([item_row, neg_context], axis=1)\n",
    "        neg_row.rating = 0\n",
    "        neg_df = neg_df.append(neg_row)   \n",
    "\n",
    "df = df.append(neg_df)\n",
    "df.sort_values(by=['user'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = df.pop('rating')\n",
    "df.insert(2, rating.name, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-design",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('MDF_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
