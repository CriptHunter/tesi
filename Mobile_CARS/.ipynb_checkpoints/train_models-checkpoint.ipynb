{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models MDF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Embedding, Flatten, Concatenate, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import rs_models\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "from implicit.evaluation import AUC_at_k, precision_at_k, train_test_split\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_split(df, x, y, n_splits=6):\n",
    "    kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(df[x], df[y]):\n",
    "        x_train, x_test = df[x].loc[train_index, :], df[x].loc[test_index, :]\n",
    "        y_train, y_test = df[y].loc[train_index], df[y].loc[test_index]\n",
    "        yield x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def kfold_train(model, param, df, context_labels=[], n_splits=2):\n",
    "    \"\"\"\n",
    "    Train a model on n split using kfold\n",
    "    model: function that returns a compiled model\n",
    "    param: dictionary that contains model parameters (learning rate, epochs, batch size...)\n",
    "    \"\"\"\n",
    "    x_labels = ['user', 'item'] \n",
    "    y_labels = 'rating'\n",
    "    df = df.sample(frac=1) # shuffle dataset\n",
    "    kfold = kfold_split(df, x_labels+context_labels, y_labels, n_splits) # generator that returns training and test index\n",
    "    idx = 0\n",
    "\n",
    "    for x_train, y_train, x_test, y_test in kfold:\n",
    "        net = model(param)\n",
    "\n",
    "        input_list = [x_train[e] for e in x_labels] # split user, item input\n",
    "        input_list = [input_list + [x_train[context_labels]] if context_labels else input_list] # add context if it's available\n",
    "        net.fit(input_list, y_train, epochs=param['epochs'], batch_size=param['batch_size'], verbose=False)\n",
    "\n",
    "        input_list = [x_test[e] for e in x_labels] # same split for test values\n",
    "        input_list = [input_list + [x_test[context_labels]] if context_labels else input_list]\n",
    "        if idx == 0: # if it is the first fold, create results array\n",
    "            results = np.array(net.evaluate(input_list, y_test, batch_size=512, verbose=False))\n",
    "        else: # else add new results to array\n",
    "            results = np.add(results, net.evaluate(input_list, y_test, batch_size=512, verbose=False))\n",
    "        idx = idx + 1\n",
    "    return results/idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating with value 1: 67.04773696519466 %\n",
      "users: 30 \t items: 338 \t rating: 72690 \t items_features: 26 \t contexts_features: 52 \t \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/MDF_final.csv')\n",
    "df = df.drop_duplicates()\n",
    "df.user = pd.factorize(df.user)[0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df.drop(['place_type_food_and_drink', 'place_type_health', 'place_type_home', 'place_type_lodging','place_type_outdoors', 'place_type_point_of_interest_establishment','place_type_public_transport_station', 'place_type_school','place_type_service', 'place_type_store', 'place_type_workplace'], axis = 1)\n",
    "\n",
    "item_labels = [i for i in list(df.columns) if i.find(\"category\") == 0] # labels that describe an item\n",
    "context_labels = list(set(df.iloc[:, 3:]) - set(item_labels)) # takes all the columns after user, item rating and remove item labels\n",
    "\n",
    "n_users = df.user.nunique()\n",
    "n_items = df.item.nunique()\n",
    "n_contexts = len(context_labels)\n",
    "    \n",
    "print(f\"rating with value 1: {df[df.rating == 1]['rating'].count() * 100 / len(df)} %\")\n",
    "print(f\"users: {n_users} \\t items: {n_items} \\t rating: {len(df)} \\t items_features: {len(item_labels)} \\t contexts_features: {n_contexts} \\t \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 2\n",
    "models_eval_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factorization \t AUC@10: 0.7237305044400053 \t precision@10: 0.4340659340659341\n"
     ]
    }
   ],
   "source": [
    "df_mf = pd.read_csv('Datasets/MDF_matrix_factorization.csv')\n",
    "ratings = coo_matrix((df_mf['rating'].astype(np.float32),\n",
    "                   (df_mf['item'],\n",
    "                    df_mf['user']))).tocsr()\n",
    "\n",
    "train, test = train_test_split(ratings)\n",
    "model = AlternatingLeastSquares(factors=128, regularization=5, iterations=20, calculate_training_loss=True)\n",
    "model.fit(train, show_progress=False)\n",
    "\n",
    "k = 10\n",
    "auc = AUC_at_k(model, train.T.tocsr(), test.T.tocsr(), K=k, show_progress=False, num_threads=4)\n",
    "precision = precision_at_k(model, train.T.tocsr(), test.T.tocsr(), K=k, show_progress=False, num_threads=4)\n",
    "print(f'Matrix factorization \\t AUC@{k}: {auc} \\t precision@{k}: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 0.46934903),\n",
       " (0, 0.38898903),\n",
       " (71, 0.35058314),\n",
       " (2, 0.34666178),\n",
       " (14, 0.28367728),\n",
       " (68, 0.26874757),\n",
       " (75, 0.18540025),\n",
       " (135, 0.18322161),\n",
       " (65, 0.16168226),\n",
       " (49, 0.1440304),\n",
       " (51, 0.13449614),\n",
       " (124, 0.13064016),\n",
       " (111, 0.12898892),\n",
       " (156, 0.12302325),\n",
       " (39, 0.10786478),\n",
       " (93, 0.10447591),\n",
       " (85, 0.10263157),\n",
       " (204, 0.09342629),\n",
       " (102, 0.08297372),\n",
       " (163, 0.076272056),\n",
       " (191, 0.076272056),\n",
       " (192, 0.076272056),\n",
       " (193, 0.076272056),\n",
       " (194, 0.076272056),\n",
       " (196, 0.076272056),\n",
       " (198, 0.076272056),\n",
       " (199, 0.076272056),\n",
       " (200, 0.076272056),\n",
       " (201, 0.076272056),\n",
       " (202, 0.076272056),\n",
       " (203, 0.076272056),\n",
       " (105, 0.076272056),\n",
       " (76, 0.068405),\n",
       " (59, 0.066314),\n",
       " (162, 0.06390548),\n",
       " (142, 0.06019838),\n",
       " (141, 0.06019838),\n",
       " (140, 0.06019838),\n",
       " (139, 0.06019838),\n",
       " (138, 0.06019838),\n",
       " (137, 0.06019838),\n",
       " (134, 0.06019838),\n",
       " (133, 0.06019838),\n",
       " (132, 0.06019838),\n",
       " (47, 0.06019838),\n",
       " (99, 0.057245124),\n",
       " (153, 0.05710817),\n",
       " (34, 0.05653026),\n",
       " (91, 0.0548299),\n",
       " (61, 0.05378414),\n",
       " (103, 0.049760237),\n",
       " (69, 0.048850708),\n",
       " (160, 0.047996335),\n",
       " (157, 0.04675116),\n",
       " (161, 0.046751156),\n",
       " (164, 0.046751156),\n",
       " (165, 0.046751156),\n",
       " (167, 0.046751156),\n",
       " (159, 0.046751156),\n",
       " (158, 0.046751156),\n",
       " (155, 0.046751156),\n",
       " (181, 0.045951318),\n",
       " (73, 0.042267375),\n",
       " (67, 0.041687272),\n",
       " (120, 0.04061649),\n",
       " (112, 0.039403237),\n",
       " (109, 0.03771717),\n",
       " (56, 0.0375828),\n",
       " (101, 0.037388586),\n",
       " (308, 0.03159275),\n",
       " (29, 0.031010613),\n",
       " (63, 0.031008825),\n",
       " (66, 0.031008823),\n",
       " (62, 0.031008823),\n",
       " (58, 0.031008823),\n",
       " (72, 0.031008821),\n",
       " (186, 0.03026226),\n",
       " (183, 0.029323518),\n",
       " (184, 0.029323518),\n",
       " (188, 0.029323518),\n",
       " (190, 0.029323518),\n",
       " (187, 0.029323516),\n",
       " (178, 0.027360337),\n",
       " (171, 0.026302665),\n",
       " (143, 0.023121405),\n",
       " (218, 0.023084173),\n",
       " (106, 0.022775294),\n",
       " (127, 0.022775292),\n",
       " (123, 0.022775292),\n",
       " (122, 0.022775292),\n",
       " (118, 0.022775292),\n",
       " (117, 0.022775292),\n",
       " (116, 0.022775292),\n",
       " (115, 0.022775292),\n",
       " (114, 0.022775292),\n",
       " (110, 0.022775292),\n",
       " (107, 0.022775292),\n",
       " (119, 0.02277529),\n",
       " (113, 0.02277529),\n",
       " (250, 0.022285618),\n",
       " (231, 0.02193699),\n",
       " (52, 0.02080106),\n",
       " (86, 0.020142065),\n",
       " (282, 0.01945834),\n",
       " (88, 0.019203369),\n",
       " (84, 0.019203369),\n",
       " (79, 0.019203369),\n",
       " (78, 0.019203369),\n",
       " (74, 0.019203369),\n",
       " (89, 0.019203367),\n",
       " (82, 0.019203367),\n",
       " (81, 0.019203365),\n",
       " (77, 0.018820172),\n",
       " (294, 0.01839947),\n",
       " (291, 0.0183015),\n",
       " (293, 0.0183015),\n",
       " (244, 0.01787299),\n",
       " (97, 0.01784188),\n",
       " (100, 0.017841877),\n",
       " (98, 0.017841877),\n",
       " (96, 0.017841877),\n",
       " (31, 0.01728017),\n",
       " (27, 0.01728017),\n",
       " (33, 0.017280169),\n",
       " (50, 0.017229034),\n",
       " (36, 0.017229034),\n",
       " (273, 0.017154302),\n",
       " (166, 0.0171543),\n",
       " (121, 0.0171543),\n",
       " (275, 0.0171543),\n",
       " (276, 0.0171543),\n",
       " (278, 0.0171543),\n",
       " (279, 0.0171543),\n",
       " (280, 0.0171543),\n",
       " (281, 0.0171543),\n",
       " (283, 0.0171543),\n",
       " (285, 0.0171543),\n",
       " (286, 0.0171543),\n",
       " (287, 0.0171543),\n",
       " (288, 0.0171543),\n",
       " (290, 0.0171543),\n",
       " (292, 0.0171543),\n",
       " (295, 0.017154299),\n",
       " (149, 0.016627803),\n",
       " (238, 0.016627803),\n",
       " (241, 0.016627803),\n",
       " (243, 0.016627803),\n",
       " (245, 0.016627803),\n",
       " (246, 0.016627803),\n",
       " (247, 0.016627803),\n",
       " (248, 0.016627803),\n",
       " (249, 0.016627803),\n",
       " (175, 0.01610179),\n",
       " (177, 0.01610179),\n",
       " (179, 0.01610179),\n",
       " (180, 0.01610179),\n",
       " (42, 0.014653556),\n",
       " (173, 0.01373044),\n",
       " (172, 0.01373044),\n",
       " (170, 0.01373044),\n",
       " (168, 0.01373044),\n",
       " (174, 0.013730438),\n",
       " (211, 0.012572224),\n",
       " (209, 0.012572224),\n",
       " (213, 0.012572223),\n",
       " (212, 0.012572223),\n",
       " (208, 0.012572223),\n",
       " (207, 0.012572223),\n",
       " (206, 0.012572223),\n",
       " (205, 0.012572223),\n",
       " (228, 0.012405724),\n",
       " (263, 0.011825625),\n",
       " (235, 0.011825625),\n",
       " (270, 0.011825622),\n",
       " (236, 0.011713123),\n",
       " (234, 0.011258545),\n",
       " (237, 0.011258544),\n",
       " (226, 0.011258544),\n",
       " (225, 0.011258544),\n",
       " (223, 0.011258544),\n",
       " (222, 0.011258544),\n",
       " (189, 0.011258544),\n",
       " (221, 0.0112585435),\n",
       " (217, 0.0112585435),\n",
       " (232, 0.011258543),\n",
       " (230, 0.011258543),\n",
       " (229, 0.011258543),\n",
       " (227, 0.011258543),\n",
       " (220, 0.011258543),\n",
       " (219, 0.011258543),\n",
       " (216, 0.011258543),\n",
       " (215, 0.011258543),\n",
       " (214, 0.011258543),\n",
       " (269, 0.010678446),\n",
       " (267, 0.010678446),\n",
       " (266, 0.010678446),\n",
       " (264, 0.010678444),\n",
       " (258, 0.010361992),\n",
       " (256, 0.010361992),\n",
       " (253, 0.010361992),\n",
       " (251, 0.010361992),\n",
       " (257, 0.01036199),\n",
       " (254, 0.01036199),\n",
       " (150, 0.010357002),\n",
       " (154, 0.010357001),\n",
       " (80, 0.010357),\n",
       " (144, 0.010357),\n",
       " (147, 0.010357),\n",
       " (148, 0.010357),\n",
       " (54, 0.008704174),\n",
       " (83, 0.0035492245),\n",
       " (305, 0.0024020304),\n",
       " (297, 0.0016017428),\n",
       " (299, 0.0016017428),\n",
       " (315, 0.0012451843),\n",
       " (313, 0.0012451842),\n",
       " (317, 0.0012451825),\n",
       " (310, 0.0012451824),\n",
       " (312, 0.0012451824),\n",
       " (314, 0.0012451821),\n",
       " (311, 0.0012451819),\n",
       " (316, 0.0012451805),\n",
       " (129, 0.0012113207),\n",
       " (130, 0.0012113207),\n",
       " (131, 0.0012113206),\n",
       " (307, 0.0011568444),\n",
       " (302, 0.0011568442),\n",
       " (303, 0.0011568442),\n",
       " (304, 0.0011568437),\n",
       " (321, 0.0011472078),\n",
       " (324, 0.0011472078),\n",
       " (334, 0.0011472071),\n",
       " (323, 0.0011472069),\n",
       " (325, 0.0011472069),\n",
       " (330, 0.0011472069),\n",
       " (333, 0.0011472069),\n",
       " (337, 0.0011472066),\n",
       " (309, 0.0011472066),\n",
       " (318, 0.0011472066),\n",
       " (335, 0.0011472066),\n",
       " (336, 0.0011472066),\n",
       " (329, 0.0011472064),\n",
       " (322, 0.0011472062),\n",
       " (328, 0.0011472062),\n",
       " (319, 0.0011472057),\n",
       " (320, 0.0011472057),\n",
       " (332, 0.0011472055),\n",
       " (261, 0.00093875),\n",
       " (262, 0.0009387499),\n",
       " (95, 0.0009387497),\n",
       " (260, 0.00093874964),\n",
       " (300, 0.00045454348),\n",
       " (301, 0.0004545434),\n",
       " (298, 0.00045454307),\n",
       " (44, 0.00020965701),\n",
       " (259, 0.0),\n",
       " (35, 0.0),\n",
       " (90, 0.0),\n",
       " (48, 0.0),\n",
       " (32, 0.0),\n",
       " (268, 0.0),\n",
       " (70, 0.0),\n",
       " (271, 0.0),\n",
       " (272, 0.0),\n",
       " (60, 0.0),\n",
       " (296, 0.0),\n",
       " (289, 0.0),\n",
       " (284, 0.0),\n",
       " (64, 0.0),\n",
       " (169, 0.0),\n",
       " (274, 0.0),\n",
       " (92, 0.0),\n",
       " (252, 0.0),\n",
       " (94, 0.0),\n",
       " (242, 0.0),\n",
       " (25, 0.0),\n",
       " (240, 0.0),\n",
       " (239, 0.0),\n",
       " (104, 0.0),\n",
       " (233, 0.0),\n",
       " (108, 0.0),\n",
       " (224, 0.0),\n",
       " (125, 0.0),\n",
       " (126, 0.0),\n",
       " (128, 0.0),\n",
       " (210, 0.0),\n",
       " (136, 0.0),\n",
       " (197, 0.0),\n",
       " (326, 0.0),\n",
       " (327, 0.0),\n",
       " (195, 0.0),\n",
       " (185, 0.0),\n",
       " (145, 0.0),\n",
       " (331, 0.0),\n",
       " (146, 0.0),\n",
       " (182, 0.0),\n",
       " (151, 0.0),\n",
       " (152, 0.0),\n",
       " (176, 0.0),\n",
       " (277, 0.0)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = model.recommend(10, ratings, N=300)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuMF \t accuracy: 86.62677109241486% \t AUC: 0.921710729598999 \t precision: 0.9618946611881256 \t recall: 0.8339621722698212\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'n_users': n_users,\n",
    "    'n_items': n_items,\n",
    "    'n_contexts': n_contexts,\n",
    "    'learn_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 10\n",
    "}   \n",
    "\n",
    "\n",
    "std_dev, accuracy, auc, precision, recall = kfold_train(rs_models.NeuMF, param, df, n_splits=n_splits)\n",
    "models_eval_metrics['NeuMF'] = [accuracy, auc, precision, recall]\n",
    "print(f\"NeuMF \\t accuracy: {accuracy*100}% \\t AUC: {auc} \\t precision: {precision} \\t recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECAM NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECAM NeuMF \t accuracy: 89.66570198535919% \t AUC: 0.95646071434021 \t precision: 0.9588409960269928 \t recall: 0.8838070034980774\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'n_users': n_users,\n",
    "    'n_items': n_items,\n",
    "    'n_contexts': n_contexts,\n",
    "    'learn_rate': 0.001,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 10\n",
    "}  \n",
    "\n",
    "std_dev, accuracy, auc, precision, recall = kfold_train(rs_models.ECAM_NeuMF, param, df, context_labels=context_labels, n_splits=n_splits)\n",
    "models_eval_metrics['ECAM NeuMF'] = [accuracy, auc, precision, recall]\n",
    "print(f\"ECAM NeuMF \\t accuracy: {accuracy*100}% \\t AUC: {auc} \\t precision: {precision} \\t recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier \t accuracy: 89.23510799284632% \t AUC: 0.949972529684603 \t precision: 0.8976890515356051 \t recall: 0.9476025616406528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "ffnet = KerasClassifier(build_fn=rs_models.mobile_model, neurons=100, layers=3, learn_rate=0.005, epochs=10, batch_size=64, verbose=False)\n",
    "x = df[item_labels+context_labels]\n",
    "y = df['rating']\n",
    "scores = cross_validate(ffnet, x, y, cv=KFold(shuffle=True, n_splits=n_splits, random_state=42), scoring=['accuracy', 'roc_auc', 'precision', 'recall'])\n",
    "accuracy = np.average(scores['test_accuracy'])\n",
    "auc = np.average(scores['test_roc_auc'])\n",
    "precision = np.average(scores['test_precision'])\n",
    "recall = np.average(scores['test_recall'])\n",
    "models_eval_metrics['Classifier'] = [accuracy, auc, precision, recall]\n",
    "print(f\"Classifier \\t accuracy: {accuracy*100}% \\t AUC: {auc} \\t precision: {precision} \\t recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NeuMF \t Accuracy: 86.62677109241486% \t AUC: 0.921710729598999 \t Precision: 0.9618946611881256 \t Recall: 0.8339621722698212\n",
      "Model: ECAM NeuMF \t Accuracy: 89.66570198535919% \t AUC: 0.95646071434021 \t Precision: 0.9588409960269928 \t Recall: 0.8838070034980774\n"
     ]
    }
   ],
   "source": [
    "n_models = len(models_eval_metrics) # number of different models\n",
    "models_name = [x[0] for x in models_eval_metrics.items()] \n",
    "\n",
    "accuracy = [x[0] for x in models_eval_metrics.values()]\n",
    "auc = [x[1] for x in models_eval_metrics.values()]\n",
    "precision = [x[2] for x in models_eval_metrics.values()]\n",
    "recall = [x[3] for x in models_eval_metrics.values()]\n",
    "\n",
    "index = np.arange(n_models)\n",
    "bar_width = 0.20\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# AUC bar\n",
    "rect1 = plt.bar(index + bar_width, auc, bar_width, color='b', label='AUC')\n",
    "\n",
    "# accuracy bar\n",
    "rect2 = plt.bar(index, accuracy, bar_width, color='#ff7b00', label='Accuracy')\n",
    "\n",
    "# precision bar\n",
    "rect3 = plt.bar(index + bar_width*2, precision, bar_width, color='g', label='Precision')\n",
    "\n",
    "# recall bar\n",
    "rect2 = plt.bar(index + bar_width*3, recall, bar_width, color='r', label='Recall')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Prediction results')\n",
    "plt.xticks(index + bar_width * 3/2, models_name) # labels position\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('prediction_results.png')\n",
    "plt.show()\n",
    "\n",
    "for key, item in models_eval_metrics.items():\n",
    "    print(f'Model: {key} \\t Accuracy: {item[0]*100}% \\t AUC: {item[1]} \\t Precision: {item[2]} \\t Recall: {item[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
