{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "considered-language",
   "metadata": {},
   "source": [
    "# MDF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "numerous-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import holidays\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-louisiana",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "killing-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nan_category(df):\n",
    "    \"\"\"\n",
    "    System apps like camera and gallery have NaN category, and different name for the same app (ex. samsung camera and huawei camera)\n",
    "    This function fix the category and assign a common name to system apps\n",
    "    \"\"\"\n",
    "    df.loc[df['app'].str.contains('camera'), 'category'] = 'PHOTOGRAPHY' # change category from NaN\n",
    "    df.loc[df['app'].str.contains('camera'), 'app'] = 'camera'  # change app name, all camera apps from various brands are equivalent\n",
    "    \n",
    "    df.loc[df['app'].str.contains('com.android.incallui'), 'category'] = 'COMMUNICATION' # incallui is the interface during a call\n",
    "    \n",
    "    df.loc[df['app'].str.contains('mail'), 'category'] = 'PRODUCTIVITY'\n",
    "    df.loc[df['app'].str.contains('com.google.android.gm'), 'category'] = 'PRODUCTIVITY' # change gmail category from communication to productivity\n",
    "    \n",
    "    df.loc[df['app'].str.contains('gallery'), 'category'] = 'PHOTOGRAPHY' # change category from NaN\n",
    "    df.loc[df['app'].str.contains('gallery'), 'app'] = 'gallery'  # change app name, all gallery apps from various brands are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "residential-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wifi_scans(folder_path):\n",
    "    \"\"\"\n",
    "    Opens wifi_scans.csv file\n",
    "    group by time and assign true to a group only if there is at least one row with connected == true\n",
    "    skips the process if the file wifi_scans2.csv already exists\n",
    "    \"\"\"\n",
    "    if os.path.isfile(folder_path+'/wifi_scans2.csv'):\n",
    "        return\n",
    "    a = pd.read_csv(folder_path+'/wifi_scans.csv')\n",
    "    b = a[['time', 'connected']].groupby(['time'], as_index=False).any() # any() returns true if at least one entry is true\n",
    "    b.to_csv(folder_path+'/wifi_scans2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pediatric-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_row(file_path, columns, dt):\n",
    "    \"\"\"\n",
    "    finds the row in a dataframe whose time column is closest to dt\n",
    "\n",
    "    :file_path: CSV file location on disk\n",
    "    :columns: columns to read when opening the file\n",
    "    :dt: time in ms\n",
    "    :return: closest row as numpy array\n",
    "    \"\"\" \n",
    "    df = pd.read_csv(file_path, header=0, usecols=['time']+columns) # read only selected CSV columns + time column\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms') # convert from ms to date\n",
    "    df.sort_values('time', inplace=True)\n",
    "    df.drop_duplicates(subset='time', keep=\"first\", inplace=True)\n",
    "    df.set_index('time', inplace=True)\n",
    "    closest = df.iloc[[df.index.get_loc(dt, method='nearest')]].values[0] # find nearest row to time dt\n",
    "    return np.asarray(closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "finite-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary structured as file : columns\n",
    "file_dict = {'activities.csv': ['in_vehicle', 'on_bicycle', 'on_foot', 'running', 'still', 'tilting', 'walking', 'unknown'], \n",
    "             'audio.csv': ['ringer_mode', 'alarm_volume', 'music_volume', 'notifications_volume', 'ring_volume', 'music_active', 'speaker_on', 'headset_connected'],\n",
    "             'battery.csv': ['level', 'charging'],\n",
    "             'display.csv': ['state', 'rotation'],\n",
    "             'weather.csv': ['temp', 'humidity', 'pressure', 'wind_speed', 'wind_deg',  'clouds', 'rain_last3h'],\n",
    "             'wifi_scans2.csv': ['connected'],\n",
    "             'location.csv': ['label', 'place_type']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "departmental-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Datasets/MDF/'\n",
    "# system apps like launcher,package manager, settings, ota...\n",
    "ignored_apps = \"\"\"it.cnr.iit.sensapp com.android.systemui com.sec.android.app.launcher com.android.settings com.android.vending\n",
    "                  com.android.captiveportallogin com.google.android.packageinstaller com.teslacoilsw.launcher com.android.packageinstaller\n",
    "                  com.samsung.android.MtpApplication com.sec.android.emergencylauncher com.wssyncmldm com.huawei.android.launcher\n",
    "                  com.huawei.systemmanager com.asus.launcher android com.asus.ime com.asus.dm com.cyanogenmod.trebuchet\n",
    "                  org.cyanogenmod.resolver com.android.launcher3 com.oneplus.ota com.samsung.android.game.gametools\n",
    "                  com.samsung.android.app.galaxyfinder com.huawei.gamebox.global com.sec.android.inputmethod com.android.phone \n",
    "                  com.samsung.android.scloud com.huawei.android.internal.app com.miui.home com.android.providers.downloads.ui\n",
    "                  com.android.printspooler com.lge.launcher3 com.lge.phonemanagement com.lge.bluetoothsetting com.lge.wifisettings\n",
    "                  com.lge.homeselector com.lge.launcher2 com.lge.lockscreensettings it.cnr.iit.contextlabeler\n",
    "                  com.sec.android.preloadinstaller com.android.server.telecom com.asus.powersaver com.android.stk\n",
    "                  it.cnr.iit.mymoviedb \"\"\".split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "collected-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in range(31): # foreach user folder\n",
    "    user_dir = data_path + 'user_' + str(user)\n",
    "    filter_wifi_scans(user_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "advance-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▉                                                                            | 1/12 [00:00<00:01,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 22.43it/s]\n",
      "  0%|                                                                                          | 0/918 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 918/918 [01:20<00:00, 11.35it/s]\n",
      "  1%|▋                                                                                 | 3/356 [00:00<00:13, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 356/356 [00:14<00:00, 25.12it/s]\n",
      "  0%|                                                                                 | 2/2557 [00:00<02:33, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2557/2557 [02:40<00:00, 15.93it/s]\n",
      "  0%|                                                                                 | 1/3879 [00:00<06:28,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3879/3879 [05:34<00:00, 11.60it/s]\n",
      "  0%|                                                                                 | 2/2746 [00:00<03:11, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2746/2746 [03:34<00:00, 12.79it/s]\n",
      "  0%|▎                                                                                 | 3/879 [00:00<00:48, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 879/879 [00:44<00:00, 19.86it/s]\n",
      "  0%|                                                                                 | 2/1330 [00:00<01:27, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1330/1330 [01:33<00:00, 14.27it/s]\n",
      "  0%|                                                                                 | 1/2992 [00:00<05:56,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2992/2992 [06:01<00:00,  8.27it/s]\n",
      "  2%|█▉                                                                                | 3/131 [00:00<00:04, 28.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:04<00:00, 28.80it/s]\n",
      "  0%|                                                                                 | 2/1793 [00:00<01:52, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1793/1793 [01:56<00:00, 15.41it/s]\n",
      "  0%|▏                                                                                | 2/1143 [00:00<01:08, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1143/1143 [01:10<00:00, 16.14it/s]\n",
      "  0%|                                                                                 | 1/4056 [00:00<08:29,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4056/4056 [07:18<00:00,  9.24it/s]\n",
      "  1%|▍                                                                                 | 2/389 [00:00<00:20, 18.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 13...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 389/389 [00:18<00:00, 21.04it/s]\n",
      "  1%|▍                                                                                 | 3/539 [00:00<00:24, 21.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 539/539 [00:32<00:00, 16.82it/s]\n",
      "  1%|█                                                                                 | 3/240 [00:00<00:10, 22.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [00:10<00:00, 23.48it/s]\n",
      "  0%|                                                                                 | 2/1925 [00:00<02:18, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1925/1925 [02:10<00:00, 14.71it/s]\n",
      "  0%|                                                                                 | 1/5624 [00:00<11:11,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5624/5624 [09:33<00:00,  9.80it/s]\n",
      "  1%|▍                                                                                 | 2/365 [00:00<00:18, 19.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 365/365 [00:14<00:00, 24.38it/s]\n",
      "  0%|                                                                                         | 0/1994 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1994/1994 [02:36<00:00, 12.75it/s]\n",
      "  0%|                                                                                 | 1/3218 [00:00<05:32,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3218/3218 [05:10<00:00, 10.35it/s]\n",
      "  0%|▏                                                                                | 2/1039 [00:00<00:57, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 21...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1039/1039 [00:58<00:00, 17.63it/s]\n",
      "  0%|▎                                                                                 | 2/448 [00:00<00:22, 19.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 22...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 448/448 [00:21<00:00, 21.03it/s]\n",
      "  0%|▏                                                                                 | 2/969 [00:00<00:48, 19.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 23...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 969/969 [00:46<00:00, 20.73it/s]\n",
      "  0%|                                                                                 | 1/3206 [00:00<07:49,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 24...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3206/3206 [05:53<00:00,  9.08it/s]\n",
      "  0%|                                                                                 | 2/1336 [00:00<01:46, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 25...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1336/1336 [01:42<00:00, 13.07it/s]\n",
      "  0%|▎                                                                                 | 3/782 [00:00<00:37, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 26...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [00:33<00:00, 23.63it/s]\n",
      "  0%|                                                                                         | 0/2815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 28...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2815/2815 [04:17<00:00, 10.94it/s]\n",
      "  0%|                                                                                 | 2/2808 [00:00<02:55, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 29...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2808/2808 [02:52<00:00, 16.29it/s]\n",
      "  0%|                                                                                         | 0/2529 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on user 30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2529/2529 [04:02<00:00, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()   \n",
    "for user in list(range(0,27)) + list(range(28,31)): # foreach user folder, skip user 27 it doesn't works for some reasons\n",
    "    print(f\"working on user {user}...\")\n",
    "    user_dir = data_path + 'user_' + str(user)\n",
    "    \n",
    "    df1 = pd.read_csv(user_dir + '/running_apps.csv', header=0) # read running apps dataframe and use it as a starting point\n",
    "    df1 = df1[~df1['app'].isin(ignored_apps)]  # ignore system apps\n",
    "    fix_nan_category(df1)  # fix gallery, camera...\n",
    "    df1 = df1[~df1.app.str.contains(\"samsung|huawei|lge|asus|xiaomi|cyanogenmod\")] # ignore brand apps\n",
    "    df1 = df1[~df1.category.isnull()]  # ignore apps with NaN category\n",
    "    df1['time'] = pd.to_datetime(df1['time'], unit='ms') # convert date from ms to datetime\n",
    "    df1.sort_values('time', inplace=True)\n",
    "    # df1.drop_duplicates(subset='time', keep=\"first\", inplace=True) # drop time duplicate\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    df1.insert(1,'user',user) # insert user ID column\n",
    "    \n",
    "    rows = []\n",
    "    for dt in tqdm(df1['time']): # foreach row in running apps dataframe find the closest row in all other dataframes using datetime\n",
    "        row = []\n",
    "        for filename, columns in file_dict.items(): # foreach csv file in user folder\n",
    "            file_path = user_dir + '/' + filename\n",
    "            row = row + get_closest_row(file_path, columns, dt).tolist() # single row with all the context features\n",
    "        rows.append(row)\n",
    "\n",
    "    df2 = pd.DataFrame(rows, columns=np.concatenate(list(file_dict.values()))) # from list of list to dataframe\n",
    "    df3 = pd.concat([df1, df2], axis=1) # concat by column\n",
    "    df = pd.concat([df, df3], axis=0) # concat by row\n",
    "    \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fourth-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('MDF_not_encoded.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('MDF_not_encoded.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-medicine",
   "metadata": {},
   "source": [
    "## Extract new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daytime_from_date(date):\n",
    "    hour = date.hour\n",
    "    if hour >= 5 and hour <= 12:\n",
    "        return 'morning'\n",
    "    elif hour >= 13 and hour <= 18:\n",
    "        return 'afternoon'\n",
    "    elif hour >= 19 and hour <= 22:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "    \n",
    "def weekday_from_date(date):\n",
    "    return date.strftime(\"%A\")\n",
    "\n",
    "def is_weekend(weekday:str):\n",
    "    return True if weekday == 'Saturday' or weekday == 'Sunday' else False\n",
    "\n",
    "it_holidays = holidays.Italy()\n",
    "\n",
    "def is_holiday(date):\n",
    "    return date in it_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daytime'] = df['time'].apply(daytime_from_date)\n",
    "df['weekday'] = df['time'].apply(weekday_from_date)\n",
    "df['is_weekend'] = df['weekday'].apply(is_weekend)\n",
    "df['is_holiday'] = df['time'].apply(is_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-event",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "### Fix labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-peace",
   "metadata": {},
   "source": [
    "**place type**: group similar labels under a more general labels (es. food, restaurant and bar under food label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "growing-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['place_type'].isin(['restaurant', 'bar', 'cafe', 'food']), 'place_type'] = 'food_and_drink'\n",
    "df.loc[df['place_type'].isin(['route', 'street', 'park', 'tourist_attraction']), 'place_type'] = 'outdoors'\n",
    "df.loc[df['place_type'].isin(['transit_station', 'bus_station', 'taxi_stand']), 'place_type'] = 'public_transport_station'\n",
    "df.loc[df['place_type'].isin(['supermarket', 'home_goods', 'bakery', 'shopping_mall', 'library', 'book_store', 'florist']), 'place_type'] = 'store'\n",
    "df.loc[df['place_type'].isin(['health', 'doctor']), 'place_type'] = 'health'\n",
    "df.loc[df['place_type'].isin(['finance', 'gas_station', 'general_contractor', 'bank', 'premise', 'lawyer', 'insurance_agency', 'hair_care', 'city_hall', 'plumber', 'pharmacy', 'police', 'veterinary', 'laundry', 'place_of_worship', 'university', 'moving_company', 'post_office', 'car_repair', 'real_estate_agency', 'painter', 'car_wash', 'local_government_office', 'beauty_salon', 'electrician', 'car_rental', 'funeral_home', 'fire_station', 'travel_agency']), 'place_type'] = 'service'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-formation",
   "metadata": {},
   "source": [
    "**category**: group all GAME subcategories under GAME label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "functioning-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category'].str.contains('GAME'), 'category'] = 'GAME'\n",
    "df.loc[df['category'].isin([' COMMUNICATION']), 'category'] = 'COMMUNICATION' # fix communication category with space at the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-termination",
   "metadata": {},
   "source": [
    "### App\n",
    "Convert **app** from package name to unique IDs and rename to item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "minute-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.app = pd.factorize(df.app)[0]\n",
    "df = df.rename(columns={'app': 'item'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-paste",
   "metadata": {},
   "source": [
    "### Category\n",
    "**Category** is one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['category'], prefix='category')), axis=1)\n",
    "df.pop('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-excess",
   "metadata": {},
   "source": [
    "### Activities\n",
    "**in_vehicle, on_bicycle, on_foot, running, still, tilting, walking, unknown** represent the probability from 0 to 100 that the user is doing an activity. These features are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = 'in_vehicle on_bicycle on_foot running still tilting walking unknown'.split()\n",
    "df[activities] = df[activities].apply(lambda x: x/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-irrigation",
   "metadata": {},
   "source": [
    "### Volume\n",
    "- **ringer_mode** is one hot encoded\n",
    "- **alarm_volume, music_volume, notifications_volume, ring_volume, music_active, speaker_on, headset_connected** are already normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['ringer_mode'], prefix='ringer_mode')), axis=1)\n",
    "df.pop('ringer_mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-daisy",
   "metadata": {},
   "source": [
    "### Battery\n",
    "- Battery **level** goes from 0 to 1, where 1 is full charged, it is converted to a categorical variable and then one-hot encoded\n",
    "- **charging** is boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_battery_status(lv):\n",
    "    lv = lv * 100\n",
    "    if lv >= 80:\n",
    "        return 'charged'\n",
    "    elif lv >= 60 and lv < 80:\n",
    "        return 'quite charged'\n",
    "    elif lv >= 40 and lv < 60:\n",
    "        return 'half charged'\n",
    "    elif lv >= 20 and lv < 40:\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'very low'\n",
    "\n",
    "df['level'] = df['level'].apply(get_battery_status)\n",
    "df = pd.concat((df, pd.get_dummies(df['level'], prefix='battery')), axis=1)\n",
    "df.pop('level')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-exclusive",
   "metadata": {},
   "source": [
    "### Display\n",
    "- **state** can be 1,2,3,4\n",
    "- **rotation** can be 0,1,3\n",
    "\n",
    "Both variables are one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, pd.get_dummies(df['state'], prefix='display_state')), axis=1)\n",
    "df = pd.concat((df, pd.get_dummies(df['rotation'], prefix='display_rotation')), axis=1)\n",
    "df.pop('state')\n",
    "df.pop('rotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-rescue",
   "metadata": {},
   "source": [
    "### Weather\n",
    "- **temp**, **humidity, pressure, wind_speed, wind_deg**, **clouds** are normalized\n",
    "- **rain_last3h** is transformed into a boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rain_last3h'] = df['rain_last3h'].apply(lambda x: 1 if x > 0 else 0) # true if it rained\n",
    "\n",
    "cols_to_norm = 'temp humidity pressure wind_speed wind_deg clouds'.split()\n",
    "df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-seeker",
   "metadata": {},
   "source": [
    "### Place and date\n",
    "**place_type, daytime, weekday** are one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'place_type daytime weekday'.split()\n",
    "for e in cols:\n",
    "    df = pd.concat((df, pd.get_dummies(df[e], prefix=e)), axis=1)\n",
    "    df.pop(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-allowance",
   "metadata": {},
   "source": [
    "### Boolean to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'music_active speaker_on headset_connected connected is_weekend is_holiday'.split():\n",
    "    x[col] = x[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-ridge",
   "metadata": {},
   "source": [
    "### Add rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "single-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop('time')\n",
    "df['rating'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-capability",
   "metadata": {},
   "source": [
    "## Negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "atlantic-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "all_labels = df.label.unique() # all possible context of a single user\n",
    "\n",
    "items_labels = {} # dictionary that contains in which contexts an item has been used\n",
    "for item in df.item.unique():\n",
    "    items_labels[item] = df[df.item == item]['label'].unique()\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    item = row['item']\n",
    "    pos_labels = items_labels[item]  # contexts in which an item has been used\n",
    "    neg_labels = list(set(all_labels) - set(pos_labels))  # contexts in which an item has NOT been used\n",
    "    for neg in neg_labels: # generate a new negative sample foreach negative label\n",
    "        neg_context = df.loc[(df.item != item) & (df.label == neg)].sample(n=1) # take a random item with negative context\n",
    "        neg_context = neg_context.iloc[:, 4:] # keep only the context\n",
    "        item_row = pd.DataFrame(row.iloc[0:4]).transpose() # take user, item, rating\n",
    "        item_row.reset_index(drop=True, inplace=True) # reset index for concat\n",
    "        neg_context.reset_index(drop=True, inplace=True)\n",
    "        neg_row = pd.concat([item_row, neg_context], axis=1)\n",
    "        neg_row.rating = 0\n",
    "        neg_df = neg_df.append(neg_row)   \n",
    "\n",
    "df = df.append(neg_df)\n",
    "df.sort_values(by=['user'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "powered-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('MDF_not_encoded_neg_sampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-azerbaijan",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('MDF_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
