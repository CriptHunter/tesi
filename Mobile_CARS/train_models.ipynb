{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Embedding, Flatten, Concatenate, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import rs_models\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import implicit\n",
    "from implicit.evaluation import AUC_at_k, precision_at_k, train_test_split\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name : str):\n",
    "    if dataset == 'mdf':\n",
    "        df = pd.read_csv('Datasets/MDF_social/MDF_with_social_features.csv')\n",
    "        df_mf = pd.read_csv('Datasets/MDF_matrix_factorization.csv')\n",
    "        df = df.drop(columns='time')\n",
    "        df = df.drop_duplicates()\n",
    "        #df = df[df.item != 2]\n",
    "        # df = df.drop(['place_type_food_and_drink', 'place_type_health', 'place_type_home', 'place_type_lodging','place_type_outdoors', 'place_type_point_of_interest_establishment','place_type_public_transport_station', 'place_type_school','place_type_service', 'place_type_store', 'place_type_workplace'], axis = 1)\n",
    "        df = df.reset_index(drop=True)\n",
    "        context_labels = list(df.columns[3:66])\n",
    "        item_labels = list(df.columns[66:92])\n",
    "        user_labels = list(df.columns[92:106])\n",
    "        social_labels = list(df.columns[106:])\n",
    "\n",
    "    elif dataset == 'frappe':\n",
    "        df = pd.read_csv('Datasets/frappe dataset/frappe_final.csv')\n",
    "        df_mf = pd.read_csv('Datasets/frappe dataset/frappe_matrix_factorization.csv')\n",
    "        context_labels = list(df.columns[3:27])\n",
    "        item_labels = list(df.columns[27:54])\n",
    "        user_labels = list(df.columns[54:])\n",
    "        social_labels = []\n",
    "    return df, df_mf, user_labels, item_labels, context_labels, social_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mdf'\n",
    "df, df_mf, user_labels, item_labels, context_labels, social_labels = load_dataset(dataset)\n",
    "\n",
    "n_users = df.user.nunique()\n",
    "n_items = df.item.nunique()\n",
    "n_contexts = len(context_labels)\n",
    "\n",
    "print(f\"rating with value 1: {df[df.rating == 1]['rating'].count() * 100 / len(df)} %\")\n",
    "print(f\"users: {n_users} \\t items: {n_items} \\t rating: {len(df)}\")\n",
    "print(f\"user_features: {len(user_labels)} \\t items_features: {len(item_labels)} \\t social_features: {len(social_labels)} \\t contexts_features: {n_contexts} \\t \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10 # k-fold number of split\n",
    "models_eval_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS matrix factorization\n",
    "Alternating least square matrix factorization from implicit library\n",
    "\n",
    "https://implicit.readthedocs.io/en/latest/als.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings = coo_matrix((df_mf['rating'].astype(np.float32),\n",
    "                     (df_mf['item'],\n",
    "                      df_mf['user']))).tocsr()\n",
    "\n",
    "auc = 0\n",
    "train, test = train_test_split(ratings, train_percentage=0.80)\n",
    "for split in range(n_splits):\n",
    "    model = AlternatingLeastSquares(factors=64, regularization=10, iterations=1, calculate_training_loss=True)\n",
    "    model.fit(train, show_progress=False)\n",
    "    auc = auc + rs_models.mf_AUC(model, train, test)\n",
    "auc = auc / n_splits\n",
    "print(f\"ALS \\t AUC: {auc}\")\n",
    "models_eval_metrics['ALS'] = [0, auc, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "ratings = coo_matrix((df['rating'].astype(np.float32),\n",
    "                     (df['item'],\n",
    "                      df['user']))).tocsr()\n",
    "\n",
    "auc = 0\n",
    "train, test = train_test_split(ratings, train_percentage=0.80)\n",
    "for split in range(n_splits):\n",
    "    model = AlternatingLeastSquares(factors=128, regularization=5, iterations=10, calculate_training_loss=True)\n",
    "    model.fit(train, show_progress=False)\n",
    "    auc = auc + rs_models.mf_AUC2(model, train, test)\n",
    "auc = auc / n_splits\n",
    "print(f\"ALS \\t AUC: {auc}\")\n",
    "models_eval_metrics['ALS'] = [0, auc, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_users': n_users,\n",
    "    'n_items': n_items,\n",
    "    'n_contexts': n_contexts,\n",
    "    'learn_rate': 0.001,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 10\n",
    "}   \n",
    "\n",
    "\n",
    "std_dev, accuracy, auc, precision, recall = rs_models.kfold_train(rs_models.NeuMF, param, df, n_splits=n_splits)\n",
    "models_eval_metrics['NeuMF'] = [accuracy, auc, precision, recall]\n",
    "print(f\"NeuMF \\t accuracy: {accuracy*100}% \\t AUC: {auc} \\t precision: {precision} \\t recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECAM NeuMF\n",
    "NeuMF model that takes as input also a physical context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_users': n_users,\n",
    "    'n_items': n_items,\n",
    "    'n_contexts': n_contexts,\n",
    "    'learn_rate': 0.001,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 10\n",
    "}  \n",
    "\n",
    "std_dev, accuracy, auc, precision, recall = rs_models.kfold_train(rs_models.ECAM_NeuMF, param, df, context_labels=context_labels, n_splits=n_splits)\n",
    "models_eval_metrics['ECAM NeuMF'] = [accuracy, auc, precision, recall]\n",
    "print(f\"ECAM NeuMF \\t accuracy: {accuracy*100}% \\t AUC: {auc} \\t precision: {precision} \\t recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnet = KerasClassifier(build_fn=rs_models.mobile_model, neurons=100, layers=3, learn_rate=0.005, epochs=10, batch_size=128, verbose=False)\n",
    "x = df[item_labels + user_labels + social_labels + context_labels]\n",
    "y = df['rating']\n",
    "\n",
    "scores = cross_validate(ffnet, x, y, cv=KFold(shuffle=True, n_splits=n_splits, random_state=42), scoring=['accuracy', 'roc_auc', 'precision', 'recall'])\n",
    "\n",
    "accuracy = np.average(scores['test_accuracy'])\n",
    "auc = np.average(scores['test_roc_auc'])\n",
    "precision = np.average(scores['test_precision'])\n",
    "recall = np.average(scores['test_recall'])\n",
    "models_eval_metrics['Classifier'] = [accuracy, auc, precision, recall]\n",
    "\n",
    "print(f\"Classifier \\t accuracy: {accuracy*100}% \\t AUC: {auc} \\t precision: {precision} \\t recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all models results\n",
    "Plot AUC of ALS, NeuMF, ECAM NeuMF and classifier.\n",
    "\n",
    "The classifier use the following features: user, item, physical context, social context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(models_eval_metrics) # number of different models\n",
    "models_name = [x[0] for x in models_eval_metrics.items()] \n",
    "accuracy = [x[0] for x in models_eval_metrics.values()]\n",
    "auc = [x[1] for x in models_eval_metrics.values()]\n",
    "precision = [x[2] for x in models_eval_metrics.values()]\n",
    "recall = [x[3] for x in models_eval_metrics.values()]\n",
    "\n",
    "index = np.arange(n_models)\n",
    "bar_width = 0.50\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.bar(index, auc, bar_width, color='#408ec6', label='AUC')\n",
    "\n",
    "for i, value in enumerate(auc): # add metric value at the top of the bar\n",
    "    plt.text(i-bar_width/4, value + 0.01, str(round(value, 4))) # parameters are x position, y position, value\n",
    "    \n",
    "#plt.style.use(\"fivethirtyeight\")\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('MDF prediction results')\n",
    "plt.xticks(index, models_name) # labels position\n",
    "plt.yticks(np.arange(0, 1., 0.1))\n",
    "plt.legend()\n",
    "plt.grid(axis = 'y', linestyle = '--', linewidth = 1)\n",
    "plt.savefig(dataset + '_test_results.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier on all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = 'Datasets/MDF_social/social_datasets/'\n",
    "\n",
    "single_df_auc = models_eval_metrics['Classifier'][1] # retreive AUC of the classifier trained on the dataset without layer feature\n",
    "multi_df_auc = 0\n",
    "\n",
    "for user in tqdm(range(31)):\n",
    "    df = pd.read_csv(f'Datasets/MDF_social/social_datasets/MDF_user{user}.csv')\n",
    "    df = df.drop(columns='time')\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    x = df.iloc[:, 3:]\n",
    "    y = df['rating']\n",
    "    \n",
    "    ffnet = KerasClassifier(build_fn=rs_models.mobile_model, neurons=100, layers=3, learn_rate=0.01, epochs=20, batch_size=256, verbose=False)\n",
    "    scores = cross_validate(ffnet, x, y, cv=KFold(shuffle=True, n_splits=2, random_state=42), scoring=['roc_auc'])\n",
    "    multi_df_auc = multi_df_auc + np.average(scores['test_roc_auc'])\n",
    "    print(np.average(scores['test_roc_auc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot single model vs one model per user\n",
    "Plot AUC of the classifier trained on one dataset (the same used above) vs average AUC of 31 classifier (one per user). Users datasets have a new feature called layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = ['Single dataset', 'One dataset per user']\n",
    "auc = [single_df_auc, multi_df_auc/31]\n",
    "\n",
    "index = np.arange(len(models_name))\n",
    "bar_width = 0.20\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.bar(index, auc, bar_width, color='#408ec6', label='AUC')\n",
    "\n",
    "for i, value in enumerate(auc): # add metric value at the top of the bar\n",
    "    plt.text(i-bar_width/5, value + 0.01, str(round(value, 4))) # parameters are x position, y position, value\n",
    "    \n",
    "plt.style.use(\"default\")\n",
    "plt.xlabel('Datasets')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('AUC on users dataset')\n",
    "plt.xticks(index, models_name) # labels position\n",
    "plt.legend(bbox_to_anchor=(0.55, 1))\n",
    "plt.grid(axis = 'y', linestyle = '--', linewidth = 1)\n",
    "plt.savefig('single_vs_users_datasets.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier only on some features\n",
    "Train the classifier on parts of the available features:\n",
    "- user + item\n",
    "- user + item + social context\n",
    "- user + item + physical context\n",
    "- All available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [item_labels+user_labels, \n",
    "                item_labels+user_labels+social_labels, \n",
    "                item_labels+user_labels+context_labels,\n",
    "                item_labels+user_labels+social_labels+context_labels]\n",
    "\n",
    "parameters = [{'neurons': 100, 'layers': 3, 'learn_rate': 0.001, 'epochs': 30, 'batch_size': 256},\n",
    "              {'neurons': 100, 'layers': 3, 'learn_rate': 0.001, 'epochs': 30, 'batch_size': 64},\n",
    "              {'neurons': 100, 'layers': 3, 'learn_rate': 0.01, 'epochs': 30, 'batch_size': 256},\n",
    "              {'neurons': 100, 'layers': 3, 'learn_rate': 0.01, 'epochs': 20, 'batch_size': 256}]\n",
    "results = []\n",
    "\n",
    "y = df['rating']\n",
    "for x_labels, params in zip(train_labels, parameters):\n",
    "    x = df[x_labels]\n",
    "    ffnet = KerasClassifier(build_fn=rs_models.mobile_model, **params, verbose=False)\n",
    "    scores = cross_validate(ffnet, x, y, cv=KFold(shuffle=True, n_splits=5, random_state=42), scoring=['accuracy', 'roc_auc', 'precision', 'recall'])\n",
    "    auc = np.average(scores['test_roc_auc'])\n",
    "    print(dataset, auc)\n",
    "    results.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot classifier results on different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = ['U, I', 'U, I, S', 'U, I, P', 'U, I, S, P']\n",
    "index = np.arange(len(results))\n",
    "bar_width = 0.50\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "\n",
    "plt.bar(index, results, bar_width, color='#408ec6', label='AUC')\n",
    "\n",
    "for i, value in enumerate(results): # add metric value at the top of the bar\n",
    "    plt.text(i-bar_width/3, value + 0.01, str(round(value, 4))) # parameters are x position, y position, value\n",
    "    \n",
    "plt.style.use(\"default\")\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('moveCARS on different features')\n",
    "plt.xticks(index, models_name) # labels position\n",
    "plt.legend()\n",
    "plt.text(3.50,0.44, 'U: user\\nI: item\\nP: physical context\\nS: social context', color='black', \n",
    "         bbox=dict(facecolor='none', edgecolor='grey', boxstyle='round, pad=0.5'))\n",
    "plt.grid(axis = 'y', linestyle = '--', linewidth = 1)\n",
    "plt.savefig('moveCARS_diff_features.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFlite can't convert models with dynamic input shape, this model has a fixed input_dim\n",
    "def mobile_model_fixed_shape(neurons, layers, learn_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=107, activation='relu'))\n",
    "    for x in range(layers):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()], optimizer=Adam(lr=learn_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mobile_model_fixed_shape(100, 3, 0.01)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_tflite(model, name, x, y):\n",
    "    model.fit(x=x, y=y, epochs=10, batch_size=128)\n",
    "    model.save(f'saved_models/{name}') # save model to file\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(f'saved_models/{name}')\n",
    "    tflite_model = converter.convert() # convert to tflite\n",
    "    with open(f'saved_models/{name}.tflite', 'wb') as f: # save tflite model on file\n",
    "      f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mobile_model_fixed_shape(100, 3, 0.01)\n",
    "model_to_tflite(model, 'mobile', df[user_labels+item_labels+context_labels+social_labels], y=df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_users': n_users,\n",
    "    'n_items': n_items,\n",
    "    'n_contexts': n_contexts,\n",
    "    'learn_rate': 0.001,\n",
    "} \n",
    "\n",
    "model = rs_models.NeuMF(param)\n",
    "model_to_tflite(model, 'NeuMF', [df['user'], df['item']], y=df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rs_models.ECAM_NeuMF(param)\n",
    "model_to_tflite(model, 'ECAM_NeuMF', [df['user'], df['item'], df[context_labels]], y=df['rating'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
