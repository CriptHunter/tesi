{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enabling-father",
   "metadata": {
    "id": "dn7d0bVYO2H1"
   },
   "source": [
    "# Yelp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-decimal",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import swifter\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-thomson",
   "metadata": {
    "id": "g09QVcJRPF9Q"
   },
   "source": [
    "## Clean and merge\n",
    "Load the dataset in chunk to avoid memory overflow, delete not used column, and merge it with info about business activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-shirt",
   "metadata": {
    "id": "ybR0ntOYPIRk"
   },
   "outputs": [],
   "source": [
    "def build_yelp_dataset():\n",
    "    if os.path.exists('yelp dataset/yelp_dataset_merged.csv'):\n",
    "        return\n",
    "    df = pd.read_json('yelp dataset/yelp_academic_dataset_business.json', lines=True)\n",
    "    df = df[df.is_open == 1] # consider only opened business\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[['business_id', 'latitude', 'longitude']] # keep only this columns\n",
    "\n",
    "    chunk_list = []  # append each chunk df here \n",
    "    # open the big review dataset in little chunk\n",
    "    for count,chunk in enumerate(pd.read_json('yelp dataset/yelp_academic_dataset_review.json', lines=True, chunksize=500000)):\n",
    "        chunk = chunk[['user_id', 'business_id', 'stars', 'date']]\n",
    "        chunk = pd.merge(chunk, df, on='business_id') # merge business dataset and review dataset chunk\n",
    "        chunk_list.append(chunk)\n",
    "        print(f'processed {count + 1} chunks')\n",
    "    df_concat = pd.concat(chunk_list)\n",
    "    df_concat.to_csv('yelp dataset/yelp_dataset_merged.csv', index = False) # save dataset to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-atmosphere",
   "metadata": {},
   "source": [
    "## Dataset preprocessing\n",
    "We use the following contextual features: \n",
    "- year\n",
    "- month\n",
    "- day of the week\n",
    "- week number\n",
    "- longitude\n",
    "- latitude\n",
    "\n",
    "We extracted further contextual features from the date and location features: \n",
    "- season\n",
    "- isHoliday\n",
    "- isWeekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yelp dataset/yelp_dataset_merged.csv')\n",
    "df.rename(columns={'user_id': 'user', 'business_id': 'item'}, inplace=True)\n",
    "\n",
    "# convert user and item IDs to int64\n",
    "df.user = pd.factorize(df.user)[0]\n",
    "df.item = pd.factorize(df.item)[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a season from a date in the format d/m/Y\n",
    "def season_from_date(date):\n",
    "    year = str(date.year)\n",
    "    seasons = {1: pd.date_range(start='21/03/'+year, end='20/06/'+year), # spring\n",
    "               2: pd.date_range(start='21/06/'+year, end='22/09/'+year), # summer\n",
    "               3: pd.date_range(start='23/09/'+year, end='20/12/'+year)} # autumn\n",
    "    if date in seasons[1]:\n",
    "        return 'spring'\n",
    "    elif date in seasons[2]:\n",
    "        return 'summer'\n",
    "    elif date in seasons[3]:\n",
    "        return 'autumn'\n",
    "    else:\n",
    "        return 'winter'\n",
    "\n",
    "# faster version that consider genuary, february and march as winter and so on... you don't consider the day\n",
    "def season_from_date_fast(date):\n",
    "    seasons = np.arange(12)\n",
    "    seasons = seasons.reshape(4, 3) # reshape to a 2D matrix\n",
    "    i, j = np.where(seasons == date.month - 1) # get row where month appears\n",
    "    return i[0] + 1 # 1 = winter, 2 = spring, 3 = summer, 4 = autumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date']) # convert back to date\n",
    "df['season'] = df['date'].swifter.apply(season_from_date_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['date'].dt.dayofweek # get day of the week from date\n",
    "df['weekend'] = (df['weekday'] == 6) | (df['weekday'] == 5) # if is weekend from week day\n",
    "df['weeknumber'] = df['date'].dt.isocalendar().week # get week number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['user', 'item', 'stars', 'month', 'year', 'weekday', 'weekend', 'weeknumber', 'season', 'latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-sewing",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-return",
   "metadata": {},
   "source": [
    "- Categorical features **weekday**, **weekend** and **year** are encoded with one hot encoding.\n",
    "\n",
    "- Cyclical features **month**, **week number** and **season** are encoded into two dimensions using a sine and cosine transformation:\n",
    "$$\n",
    "x_{sin} = \\sin(\\frac{2 \\cdot \\pi \\cdot x}{max(x)}) \\\\\n",
    "x_{cos} = \\cos(\\frac{2 \\cdot \\pi \\cdot x}{max(x)})\n",
    "$$\n",
    "- Numeric features **latitude** and **longitude** are normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_cos_encoding(df, col, max_val):\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col]/max_val)\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col]/max_val)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sin_cos_encoding(df, 'month', df.month.max()) # sin cos encoding for months\n",
    "df = sin_cos_encoding(df, 'weeknumber', df.weeknumber.max()) # sin cos encoding for week number\n",
    "df = sin_cos_encoding(df, 'season', df.season.max()) # sin cos encoding for seasons\n",
    "df = df.drop(columns=['month', 'weeknumber', 'season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to one-hot encoding\n",
    "for col in ['weekday', 'year']:\n",
    "    df = pd.get_dummies(df, columns=[col], prefix = [col])\n",
    "\n",
    "df['weekend'] = df.weekend.astype('UInt8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max normalization for latitude and longitude\n",
    "mms = MinMaxScaler()\n",
    "df[['latitude','longitude']] = mms.fit_transform(df[['latitude','longitude']])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')\n",
    "ax = df[:100000].plot.scatter('latitude', 'longitude').set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'final datasets'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "df.to_csv(save_folder + '/yelp_final.csv', index = False) # save dataset to CSV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
